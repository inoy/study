# 仕事ではじめる機械学習
仕事ではじめる機械学習のノート  
https://www.oreilly.co.jp/books/9784873118215/  

---
# 目次
<!-- TOC depthFrom:1 depthTo:6 withLinks:1 updateOnSave:1 orderedList:0 -->

- [仕事ではじめる機械学習](#仕事ではじめる機械学習)
- [目次](#目次)
	- [1章  機械学習プロジェクトのはじめ方](#1章--機械学習プロジェクトのはじめ方)
		- [1.1  機械学習はどのように使われるのか](#11--機械学習はどのように使われるのか)
		- [1.2  機械学習プロジェクトの流れ](#12--機械学習プロジェクトの流れ)
			- [1.2.1  問題を定式化する](#121--問題を定式化する)
			- [1.2.2  機械学習をしなくて良い方法を考える](#122--機械学習をしなくて良い方法を考える)
			- [1.2.3  システム設計を考える](#123--システム設計を考える)
			- [1.2.4  アルゴリズムを選定する](#124--アルゴリズムを選定する)
			- [1.2.5  特徴量，教師データとログの設計をする](#125--特徴量教師データとログの設計をする)
			- [1.2.6  前処理をする](#126--前処理をする)
			- [1.2.7  学習・パラメータチューニング](#127--学習パラメータチューニング)
			- [1.2.8  システムに組み込む](#128--システムに組み込む)
		- [1.3  実システムにおける機械学習の問題点への対処方法](#13--実システムにおける機械学習の問題点への対処方法)
			- [1.3.1  人手でゴールドスタンダードを用意して，予測性能のモニタリングをする](#131--人手でゴールドスタンダードを用意して予測性能のモニタリングをする)
			- [1.3.2  予測モデルをモジュール化をしてアルゴリズムのA/Bテストができるようにする](#132--予測モデルをモジュール化をしてアルゴリズムのabテストができるようにする)
			- [1.3.3  モデルのバージョン管理をして，いつでも切り戻し可能にする](#133--モデルのバージョン管理をしていつでも切り戻し可能にする)
			- [1.3.4  データ処理のパイプラインごと保存する](#134--データ処理のパイプラインごと保存する)
			- [1.3.5  開発/本番環境の言語/フレームワークは揃える](#135--開発本番環境の言語フレームワークは揃える)
		- [1.4  機械学習を含めたシステムを成功させるには](#14--機械学習を含めたシステムを成功させるには)
		- [1.5  この章のまとめ](#15--この章のまとめ)
	- [2章  機械学習で何ができる？](#2章--機械学習で何ができる)
		- [2.1  どのアルゴリズムを選ぶべきか？](#21--どのアルゴリズムを選ぶべきか)
		- [2.2  分類](#22--分類)
			- [2.2.1  パーセプトロン](#221--パーセプトロン)
			- [2.2.2  ロジスティック回帰](#222--ロジスティック回帰)
			- [2.2.3  SVM](#223--svm)
			- [2.2.4  ニューラルネットワーク](#224--ニューラルネットワーク)
			- [2.2.5  k-NN](#225--k-nn)
			- [2.2.6  決定木，ランダムフォレスト，GBDT](#226--決定木ランダムフォレストgbdt)
		- [2.3  回帰](#23--回帰)
			- [2.3.1  線形回帰の仕組み](#231--線形回帰の仕組み)
		- [2.4  クラスタリング・次元削減](#24--クラスタリング次元削減)
			- [2.4.1  クラスタリング](#241--クラスタリング)
			- [2.4.2  次元削減](#242--次元削減)
		- [2.5  その他](#25--その他)
			- [2.5.1  推薦](#251--推薦)
			- [2.5.2  異常検知](#252--異常検知)
			- [2.5.3  頻出パターンマイニング](#253--頻出パターンマイニング)
			- [2.5.4  強化学習](#254--強化学習)
		- [2.6  この章のまとめ](#26--この章のまとめ)
	- [3章  学習結果を評価しよう](#3章--学習結果を評価しよう)
		- [3.1  分類の評価](#31--分類の評価)
			- [3.1.1  正解率を使えば良いのか？](#311--正解率を使えば良いのか)
			- [3.1.2  データ数の偏りを考慮する適合率と再現率](#312--データ数の偏りを考慮する適合率と再現率)
			- [3.1.3  F値でバランスの良い性能を見る](#313--f値でバランスの良い性能を見る)
			- [3.1.4  混同行列を知る](#314--混同行列を知る)
			- [3.1.5  多クラス分類の平均のとり方: マイクロ平均，マクロ平均](#315--多クラス分類の平均のとり方-マイクロ平均マクロ平均)
			- [3.1.6  分類モデルを比較する](#316--分類モデルを比較する)
		- [3.2  回帰の評価](#32--回帰の評価)
			- [3.2.1  平均二乗誤差](#321--平均二乗誤差)
			- [3.2.2  決定係数](#322--決定係数)
		- [3.3  機械学習を組み込んだシステムのA/Bテスト](#33--機械学習を組み込んだシステムのabテスト)
		- [3.4  この章のまとめ](#34--この章のまとめ)
	- [4章  システムに機械学習を組み込む](#4章--システムに機械学習を組み込む)
		- [4.1  システムに機械学習を含める流れ](#41--システムに機械学習を含める流れ)
		- [4.2  システム設計](#42--システム設計)
			- [4.2.1  混乱しやすい「バッチ処理」と「バッチ学習」](#421--混乱しやすいバッチ処理とバッチ学習)
			- [4.2.2  バッチ処理で学習＋予測結果をWebアプリケーションで直接算出する（リアルタイム処理で予測）](#422--バッチ処理で学習予測結果をwebアプリケーションで直接算出するリアルタイム処理で予測)
			- [4.2.3  バッチ処理で学習＋予測結果をAPI経由で利用する（リアルタイム処理で予測）](#423--バッチ処理で学習予測結果をapi経由で利用するリアルタイム処理で予測)
			- [4.2.4  バッチ処理で学習＋予測結果をDB経由で利用する（バッチ処理で予測）](#424--バッチ処理で学習予測結果をdb経由で利用するバッチ処理で予測)
			- [4.2.5  リアルタイム処理で学習をする](#425--リアルタイム処理で学習をする)
			- [4.2.6  各パターンのまとめ](#426--各パターンのまとめ)
		- [4.3  ログ設計](#43--ログ設計)
			- [4.3.1  特徴量や教師データに使いうる情報](#431--特徴量や教師データに使いうる情報)
			- [4.3.2  ログを保持する場所](#432--ログを保持する場所)
			- [4.3.3  ログを設計する上での注意点](#433--ログを設計する上での注意点)
		- [4.4  この章のまとめ](#44--この章のまとめ)
	- [5章  学習のためのリソースを収集しよう](#5章--学習のためのリソースを収集しよう)
		- [5.1  学習のためのリソースの取得方法](#51--学習のためのリソースの取得方法)
		- [5.2  公開されたデータセットやモデルを活用する](#52--公開されたデータセットやモデルを活用する)
		- [5.3  開発者自身が教師データを作る](#53--開発者自身が教師データを作る)
		- [5.4  同僚や友人などにデータ入力してもらう](#54--同僚や友人などにデータ入力してもらう)
		- [5.5  クラウドソーシングを活用する](#55--クラウドソーシングを活用する)
		- [5.6  サービスに組み込み，ユーザに入力してもらう](#56--サービスに組み込みユーザに入力してもらう)
		- [5.7  この章のまとめ](#57--この章のまとめ)
	- [6章  効果検証](#6章--効果検証)
		- [6.1  効果検証の概要](#61--効果検証の概要)
			- [6.1.1  効果検証までの道程](#611--効果検証までの道程)
			- [6.1.2  オフラインで検証しにくいポイント](#612--オフラインで検証しにくいポイント)
		- [6.2  仮説検定の枠組み](#62--仮説検定の枠組み)
			- [6.2.1  コインは歪んでいるか](#621--コインは歪んでいるか)
			- [6.2.2  二群の母比率の差の検定](#622--二群の母比率の差の検定)
			- [6.2.3  偽陽性と偽陰性](#623--偽陽性と偽陰性)
		- [6.3  仮説検定の注意点](#63--仮説検定の注意点)
			- [6.3.1  繰り返し検定をしてしまう](#631--繰り返し検定をしてしまう)
			- [6.3.2  有意差とビジネスインパクト](#632--有意差とビジネスインパクト)
			- [6.3.3  複数の検定を同時に行う](#633--複数の検定を同時に行う)
		- [6.4  因果効果の推定](#64--因果効果の推定)
			- [6.4.1  ルービンの因果モデル](#641--ルービンの因果モデル)
			- [6.4.2  セレクションバイアス](#642--セレクションバイアス)
			- [6.4.3  ランダム化比較試験](#643--ランダム化比較試験)
			- [6.4.4  過去との比較は難しい](#644--過去との比較は難しい)
		- [6.5  A/Bテスト](#65--abテスト)
			- [6.5.1  2群の抽出と標本サイズ](#651--2群の抽出と標本サイズ)
			- [6.5.2  A/Aテストによる均質さの確認](#652--aaテストによる均質さの確認)
			- [6.5.3  A/Bテストの仕組み作り](#653--abテストの仕組み作り)
			- [6.5.4  テストの終了](#654--テストの終了)
		- [6.6  この章のまとめ](#66--この章のまとめ)
	- [第II部](#第ii部)
	- [7章  映画の推薦システムをつくる](#7章--映画の推薦システムをつくる)
		- [7.1  シナリオ](#71--シナリオ)
			- [7.1.1  推薦システムとは](#711--推薦システムとは)
			- [7.1.2  応用シーン](#712--応用シーン)
		- [7.2  推薦システムをもっと知ろう](#72--推薦システムをもっと知ろう)
			- [7.2.1  データの設計と取得](#721--データの設計と取得)
			- [7.2.2  明示的データと暗黙的データ](#722--明示的データと暗黙的データ)
			- [7.2.3  推薦システムのアルゴリズム](#723--推薦システムのアルゴリズム)
			- [7.2.4  ユーザー間型協調フィルタリング](#724--ユーザー間型協調フィルタリング)
			- [7.2.5  アイテム間型協調フィルタリング](#725--アイテム間型協調フィルタリング)
			- [7.2.6  モデルベース協調フィルタリング](#726--モデルベース協調フィルタリング)
			- [7.2.7  内容ベースフィルタリング](#727--内容ベースフィルタリング)
			- [7.2.8  協調フィルタリングと内容ベースフィルタリングの得手・不得手](#728--協調フィルタリングと内容ベースフィルタリングの得手不得手)
			- [7.2.9  評価尺度](#729--評価尺度)
		- [7.3  MovieLensのデータの傾向を見る](#73--movielensのデータの傾向を見る)
		- [7.4  推薦システムの実装](#74--推薦システムの実装)
			- [7.4.1  Factorization Machineを使った推薦](#741--factorization-machineを使った推薦)
			- [7.4.2  いよいよFactorizatoin Machineで学習する](#742--いよいよfactorizatoin-machineで学習する)
			- [7.4.3  ユーザーと映画以外のコンテキストも加える](#743--ユーザーと映画以外のコンテキストも加える)
		- [7.5  この章のまとめ](#75--この章のまとめ)
	- [8章  Kickstarterの分析，機械学習を使わないという選択肢](#8章--kickstarterの分析機械学習を使わないという選択肢)
		- [8.1  KickstarterのAPIを調査する](#81--kickstarterのapiを調査する)
		- [8.2  Kickstarterのクローラを作成する](#82--kickstarterのクローラを作成する)
		- [8.3  JSONデータをCSVに変換する](#83--jsonデータをcsvに変換する)
		- [8.4  Excelで軽く眺めてみる](#84--excelで軽く眺めてみる)
		- [8.5  ピボットテーブルでいろいろと眺めてみる](#85--ピボットテーブルでいろいろと眺めてみる)
		- [8.6  達成したのにキャンセルされたプロジェクトを見てみる](#86--達成したのにキャンセルされたプロジェクトを見てみる)
		- [8.7  国別に見てみる](#87--国別に見てみる)
		- [8.8  レポートを作る](#88--レポートを作る)
		- [8.9  今後行いたいこと](#89--今後行いたいこと)
		- [8.10  おわりに](#810--おわりに)
	- [9章  Uplift Modelingによるマーケティング資源の効率化](#9章--uplift-modelingによるマーケティング資源の効率化)
		- [9.1  Uplift Modelingの四象限のセグメント](#91--uplift-modelingの四象限のセグメント)
		- [9.2  A/Bテストの拡張を通じたUplift Modelingの概要](#92--abテストの拡張を通じたuplift-modelingの概要)
		- [9.3  Uplift Modelingのためのデータセット生成](#93--uplift-modelingのためのデータセット生成)
		- [9.4  2つの予測モデルを利用したUplift Modeling](#94--2つの予測モデルを利用したuplift-modeling)
		- [9.5  Uplift Modellingの評価方法，AUUC](#95--uplift-modellingの評価方法auuc)
		- [9.6  実践的な問題での活用](#96--実践的な問題での活用)
		- [9.7  Uplift Modelingを本番投入するには](#97--uplift-modelingを本番投入するには)
		- [9.8  この章のまとめ](#98--この章のまとめ)

<!-- /TOC -->

---
## 1章  機械学習プロジェクトのはじめ方
機械学習の概要，プロジェクトの流れ，機械学習特有の問題，チームづくりについて紹介  
Pythonの機械学習ライブラリscikit-learnを使うことを前提に説明  

---
### 1.1  機械学習はどのように使われるのか
skip  

---
### 1.2  機械学習プロジェクトの流れ
以下の流れで進めると良い  
1. 解きたい課題を機械学習で解ける問題設定に落としこむ  
	　問題を定式化する -> 機械学習をしないで良い方法を考える  
1. 解くための 道具選び と 前処理  
	　システム設計を考える -> アルゴリズムを選定する  
	　-> 特徴量，教師データとログの設計をする -> 前処理をする  
1. モデルの作成  
	　学習・パラメータチューニング  
1. サービスへの組み込み  
	　システムに組み込む

機械学習で 何ができて何ができなさそうか 判断できるようになるためには  
「機械学習でこういう課題を解決した」という事例を見たとき 以下を意識して調べると良い  
- どういったアルゴリズムで解決したか  
- どのようなデータをFeatureにしているか  
- 機会学習をどのように組み込んでいるか  

#### 1.2.1  問題を定式化する
目的を明確にし 仮説を立て アクション可能なレベルにする  

例えば 目的「生産コストを減らす」から (仮説「不良が減ればコストが減る」)  
アクション可能なレベル「どこで不良が起こっているか特定するために機械学習を使う」  

この過程で ビジネス上の指標 KPI(Key Performance Indicator)を仮で良いので決める  

#### 1.2.2  機械学習をしなくて良い方法を考える
ビジネスで機械学習を利用する際に満たすべき条件  
- 大量データに対し 高速に安定して判断を求める必要がある  
- 予測結果に 一定の間違いが含まれることが許容できる  

この条件を満たしたうえで まずはMVP(\*)を作り 立てた仮説の筋が良いか悪いかを確認すべき  
　\* MVP: Minimu Viable Product 最低限の顧客価値を生み出す最小プロダクト

MVPを作る際に有用なOSS: Apache Solr や Elasticsearch の More Like This 機能

#### 1.2.3  システム設計を考える
設計で重要なポイントは以下  
- 予測結果をどういう形で利用するのか -> 詳細は [4章 システムに機械学習を組み込む](#4章--システムに機械学習を組み込む) 参照  
- 予測誤りをどこで吸収するのか  

この段階で 撤退ライン(例: 2ヵ月で90%の予測性能を達成する) を決めておくと良い  
予測性能の決め方は 3章 学習結果を評価しよう を参照  

#### 1.2.4  アルゴリズムを選定する
アルゴリズム選定の指針の詳細は [2章 機械学習で何ができる？](#2章--機械学習で何ができる) を参照  

#### 1.2.5  特徴量，教師データとログの設計をする
特徴量(Feature)の設計 の考え方  
- ビジネスドメインの知識を持った人と協力して 何がその現象に影響を与えそうか確認する  
	例: タービンの不具合検出に 過去の経験を元にハンマーで叩いた音をFeatureとした
- 後から不要なデータを削ることはできるけど 必要なデータを遡って取得することはできない  
- 晴れ, 曇りのようなFeatureはカテゴリカル変数と言い  
	ダミー変数(数値データ)に変換して処理する  
	scikit-learnでダミー変数への変換はLabelEncoder, OneHotEncoder クラスが利用可能  

教師データを用意するために  
- 質の良い正解ラベルをどのように取得するかが重要  
	正解ラベル収集の詳細は [5章 学習のためのリソースを収集しよう](#5章--学習のためのリソースを収集しよう) を参照  
- 元となる情報をWebアプリのログから取得することが よく行われる  
	Featureを抽出するためのログ設計の詳細については [4.3  ログ設計](#43--ログ設計) 参照  

#### 1.2.6  前処理をする
- テキスト形式のデータ  
	単語に分割して頻度を変えたり 低頻度を除去したり ダミー変数に変換したり
- 数値データ  
	欠損値のデータ処理をしたり 異常値を除外したり 正規化したり  

ここに多くの時間を取られる

#### 1.2.7  学習・パラメータチューニング
機械学習のパラメタを試行錯誤しながら変えて より良い結果がでるパラメタを探索する  

いきなり予測性能99.9%のような高い性能が出た場合  
過学習(Overfitting) や DataLeakage が発生していないか疑うべき  

性能改善には 誤判定した予測結果から エラー分析(何が誤りの原因か, 共通項はないか)する  

#### 1.2.8  システムに組み込む
機械学習のロジックをシステムに組み込んだら  
予測性能 と それに伴うビジネスインパクト(KPI) をモニタリングする  

入力の傾向が変わり(トレンドが変わり) 同じ予測モデルを使い続けていると  
予測性能が劣化する場合がある そのときは [手順5](#125--特徴量教師データとログの設計をする)～[7](#127--学習パラメータチューニング) に立ち戻って改善する  

改善し続けるため KPIをトラックし易いよう  
ダッシュボードを作ったり 異常時にアラートを飛ばす仕組みを作る  

---
### 1.3  実システムにおける機械学習の問題点への対処方法
機械学習システムを継続して 改善/メンテナンス するために重要なポイント について
// この章 全体的にちゃんと理解できてない感ある  

#### 1.3.1  人手でゴールドスタンダードを用意して，予測性能のモニタリングをする
定期的に 人工データセット(x, y)作成 -> 予測性能の測定 を実施してモニタリングする  

これにより 予測モデルの定期的評価(テストでき) や トレンド変化による劣化に気付ける

モニタリング用のデータセットは同じものを使い続けるのか(多分 違う)  
適当に都度作り直すのか どうやって作る?(取ってくる?)のか分からない  

#### 1.3.2  予測モデルをモジュール化をしてアルゴリズムのA/Bテストができるようにする
機械学習システムの全体像が理解できていないため  
どこをモジュール化すべきと言ってくれているのか具体的に理解できない  
各前処理 と 予測モデル生成の処理は分けるとして 他がよく分からない  

#### 1.3.3  モデルのバージョン管理をして，いつでも切り戻し可能にする
ソースコード, モデル, データ の3つをバージョン管理できるのが理想  

モデル(関数?)は どのソースコード, データから生成したかドキュメント化すると良い  

#### 1.3.4  データ処理のパイプラインごと保存する
機械学習システムのデータ パイプラインは以下  
`Originalデータ -> 前処理 -> 予測モデル生成 -> 予測値の取得`  
[1.3.3](#133--モデルのバージョン管理をしていつでも切り戻し可能にする)で指すソースコードには これらすべての処理を含めましょう という話？  

[TODO] scikit-learnに以下の機能があるらしいので この辺りを勉強すれば理解できるかも  
> 更に前処理やアルゴリズムのパイプラインを作成し、性能が最も良い組み合わせを保存することができます

#### 1.3.5  開発/本番環境の言語/フレームワークは揃える
これも見出しの通り  

マイクロサービス的なアーキ(REST APIでやり取り)に出来るなら必ずしも揃えないのもあり  
予測モデル開発 と アプリ開発で それぞれ得意な言語・フレームワークを使う  

---
### 1.4  機械学習を含めたシステムを成功させるには
成功には 以下の4者(兼務もあり)がチームに必要
- プロダクトに関するドメイン知識を持った人  
	解くべき課題は何か プロダクトのどこに機械学習の手法が必要か を考える  
	また Feature選定や データ収集の方法 を考える
- 統計や機会学習に明るい人  
	この本で説明してくれていることができる人  
- データ分析基盤を作れるエンジニアリング能力のある人  
	= データエンジニア: データを活用できるようにする分析基盤を作る人  
- 失敗しても構わないとリスクを取ってくれる責任者  
	機械学習のリスクを認識・理解したうえで お金取ってくれる/来てくれる 人  

---
### 1.5  この章のまとめ
機械学習プロジェクトの進め方とそのポイント まとめ  
- 解くべき問題の仮説を立て MVPを作りコンセプトの検証を最優先する [1.2.2](#122--機械学習をしなくて良い方法を考える)  
- 機械学習をしないことを恐れない [1.2.2](#122--機械学習をしなくて良い方法を考える)  
- 機械学習に適している問題設定かを見極める [1.2.2](#122--機械学習をしなくて良い方法を考える)  
- 予測性能とKPIの両方のモニタリングし、継続して改善を続ける [1.2.8](#128--システムに組み込む)  

---
## 2章  機械学習で何ができる？
できることを 分類, 回帰, クラスタリング, 次元削減, その他 に分けて解説  
まずは アルゴリズムをどう選ぶべきかについて  

---
### 2.1  どのアルゴリズムを選ぶべきか？
どのアルゴリズムを使えば良いか考えるには アルゴリズムの特徴を知る必要がある  
- 分類: 教師あり学習 離散データ(クラス)を予測  
- 回帰: 教師あり学習 連続値を予測  
- クラスタリング: 教師なし学習 グルーピング
- 次元削減: 教師なし学習 グラフ化や計算量削減のために高次元データを低次元にマッピング  
- その他 (これはアルゴリズム?)
	- 推薦: ユーザが好みそうなアイテムや 類似アイテムを提示  
	- 異常検知: 不審なアクセスなど 負担とは違う挙動を検知
	- 頻出パターンマイニング: データ中に高頻度で出現するパターンを抽出  
	- 強化学習: 囲碁, 将棋など 局所的には正解が不明瞭な環境でとるべき行動の方針を学習  

アルゴリズムの選択基準(本に簡略・日本語化してくれている図があるけど ここには載せない)   

<img src="https://scikit-learn.org/stable/_static/ml_map.png" width=50%>  
https://scikit-learn.org/stable/_static/ml_map.png  

アルゴリズムの選択では以下がポイント  
データセット量, 予測対象が離散データか, データセットにラベルが存在するか  

---
### 2.2  分類
教師あり学習 予測対象はカテゴリなどの離散値(クラス)  
例えば メールがスパムかどうか 画像に何が映っているか  
クラス数が2なら二値分類 3以上なら多値分類/多クラス分類  



以降 本節では 分類のアルゴリズムを紹介  



書籍内では アルゴリズムを図/グラフで直感的に理解できるようにしてくれているので  

忘れたときは図/グラフを見ると思い出しやすいと思う  



#### 2.2.1  パーセプトロン
`Feature と 学習した重み の積和`(出力値)が0以上ならクラス1 0未満ならクラス2に分類する  
活性化関数(出力値を非線形変換する関数)はステップ関数(入力値を+1/-1(0)にする関数)  
損失関数は $$max(0, -y \times h_{Θ}(x))$$ というヒンジ損失  



パーセプトロンの特徴  
- オンライン学習(≠バッチ学習)で学習する  
  つまり データを1つずつ入力して最適化する(≠全部を入れて最適化する) 詳細は[4.2.1](#421--混乱しやすいバッチ処理とバッチ学習)参照  
- 予測性能はそこそこで 学習は速い
- 過学習しやすい  
  伝統的なパーセプトロンには過学習を抑制する仕組み(正則化項の導入)が無いため  
- 線形分離可能な問題のみ解ける  



#### 2.2.2  ロジスティック回帰
パーセプトロンとの違い
- 活性化関数 シグモイド関数  
  詳細は[CourseraのMachineLearningノート](https://github.com/ysk-in/study/tree/master/MachineLearning/week03/02_HypothesisRepresentation)参照
- CostFunction $$-\sum_{i=1}^{m}y^{(i)}\log(h_{Θ}(x^{(i)})) + (1-y^{(i)})\log(1-h_{Θ}(x^{(i)}))$$
  詳細は[CourseraのMachineLearningノート](https://github.com/ysk-in/study/tree/master/MachineLearning/week03/05_SimplifiedCostFunctionAndGradientDescent)参照
- 正則化項がある  
  詳細は[CourseraのMachineLearningノート](https://github.com/ysk-in/study/tree/master/MachineLearning/week03/11_RegularizedLogisticRegression)参照  



ロジスティック回帰の特徴  
- クラスに所属する確率値が出せる(活性関数がシグモイド関数)  
- オンライン学習でもバッチ学習でも可能  
- 予測性能はまずまず 学習速度は速い  
- 過学習が防げる(正則化項がある)  
- 線形分離可能な問題のみ解ける  



#### 2.2.3  SVM

パーセプトロンを拡張したアルゴリズム 分類では非常に良く利用される  

損失関数はパーセプトロンと同じヒンジ損失だが ぎりぎり正解にもペナルティを与える



SVMの特徴  

- マージン最大化をすることで なめらかな超平面を学習できる  
  超平面をどう引けば サポートベクトル(2クラスそれぞれ最も近いデータ)までの距離を  

  最大化できるかを考える これにより既知データに対しあそびが生まれ 過学習が抑止できる  

- カーネル(Kernel)と呼ばれる方法を使い 非線形なデータを分離できる  

  線形カーネル: 直線で分離  
  RBFカーネル: 非線形に分離

  特徴量を疑似的に追加しデータを高次元にすることで 線形分離可能にする   

- 線形カーネルなら次元数の多い疎なデータも学習可能  
  疎なデータとはFeatureのほとんどが0でたまに値が入っているデータのこと  

  例えば テキストデータから単語の頻度をデータにするとき 対応する単語の種類を10,000など多くすると 疎なデータになる  

  逆にほとんどが0以外のデータは密なデータと言う 小さくリサイズした画像などが該当する  

- バッチ学習でもオンライン学習でも可能  



#### 2.2.4  ニューラルネットワーク

多層パーセプトロンとも呼ばれる  

活性化関数には近年ではReLU(Rectified Linear Unit)がよく使われる  



ニューラルネットワークの特徴  

- 非線形なデータを分離できる  
- 学習に時間がかかる  
- パラメータ数が多いので 過学習しやすい  
- 重みの初期値に依存して 局所最適解にはまりやすい  



#### 2.2.5  k-NN

k-NN(k近傍法, k-Nearest Neighbor Method)  

データのクラスを 近くのk個のデータが属するクラスの多数決で決める  



k-NNの特徴  

- データを1つずつ逐次学習する  
- 基本的に全データとの距離計算をする必要があるため 予測計算に時間がかかる  
- kの数によるがそこそこの予測性能  
- Featureのスケールが大きく違うと上手く学習できないため 正規化が必要  



#### 2.2.6  決定木，ランダムフォレスト，GBDT

##### 決定木

ツリー型のアルゴリズムの代表 決定木(Decision Tree)  

その発展形 ランダムフォレスト と Gradient Boosted  Decision Tree(GBDT)  



決定木の特徴  

- 学習したモデルを人間が見て解釈しやすい  

  学習結果としてIF-THENルールが得られるため  

- 入力データの正規化がいらない  

- カテゴリ変数や欠損値などを入力しても内部で処理してくれる  

- 特定の条件下で過学習しやすい傾向にある  
  データを条件分岐で分けて性質上  

  木の深さが深くなると学習に使えるデータ数が少なくなるため 過学習しやすい  
  これは枝刈り(剪定, Pruning)したり Feature減らしたり次元削減したりである程度は防げる  

- 非線形分離可能だが 線形分離可能な問題は不得意  
  領域の分割を繰り返し決定境界をつくるため 直線にならない  

- クラスごとのデータ数に偏りのあるデータは不得意  

- データの小さな変化に対して結果が大きく変わりやすい  

- 予測性能はまずまず  

- バッチ学習でしか学習できない  



##### ランダムフォレスト

利用するFeatureの組み合わせをいくつか用意し 性能が良い学習器の予測結果を多数決で統合  

複数の木を独立して学習するため 並列して学習できる  



##### GBDT

直列的に浅い木を学習していく勾配ブースティング法を使うアルゴリズム  

予測値と実測値のズレを目的変数として考慮し 弱点を補強しながら学習  

- 直列で学習するため時間がかかる  
  ただ 高速なライブラリ(XGBoostやLightGBM)の登場もあり 大規模データでも処理し易い
- パラメータ数が多いためチューニングにコストがかかる  
- ランダムフォレストより高い予測性能が得られる  



ランダムフォレストやGBDTのように 複数の学習結果を組み合わせる手法をアンサンブル学習と言う  



---

### 2.3  回帰

教師あり学習 入力データから連続値を予測する  

例えば 都市の電力消費量 や Webサイトのアクセス数  



各アルゴリズムの おおよその傾向  

- 線形回帰(Linear Regression): データを直線で近似するもの  
- 多項式回帰(Polynomial Regression): 曲線で近似したもの  
- Lasso回帰, Ridge回帰, Elastic Net  
  線形回帰に以下を正則化項として追加したもの
  Ridge回帰は学習した重みの2乗を(L2正則化)  
  Lasso回帰は学習した重みの絶対値を(L1正則化)  
  Elastic Netはその両方
- 回帰木(Regression Tree)
  決定機ベース 非線形なデータに対してフィッティングできる  
- SVR(Support Vector Regression)  
  SVMベース 非線形なデータに対してもフィッティングできる  

線形なデータだと分かっているときは 線形/Lasso/Ridge 回帰 または Elastic Netを用い  

それでも上手くいかない場合は 回帰木やSVRなど 非線形な回帰を用いるのが良い  



#### 2.3.1  線形回帰の仕組み

skip Courseraの内容と重複のため  



---

### 2.4  クラスタリング・次元削減

クラスタリングと次元削減について説明  



#### 2.4.1  クラスタリング

教師なし学習 主にデータの傾向をつかむために使われる 手法として例えば 以下がある  

- 階層的クラスタリング(Hierarchical Clustering): 似ている組み合わせを順番にまとめていく  

- k-means: 距離の近いもの同士をk個のグループに分割する



#### 2.4.2  次元削減

高次元のデータからできるだけ情報を保持しながら低次元のデータへ変換する  

例えば100次元データがあるとき これをを2次元にしてグラフ表現してみて 特徴を見てみる  

手法として 主成分分析(PCA, Principal Component Analysis) や t-SNE(特に可視化に有効) がある  



---

### 2.5  その他

その他　機械学習 や データマイニング関連でよく取り組まれるトピック について  



#### 2.5.1  推薦

ユーザが好みそうなアイテム や 類似するアイテムを提示する  

ユーザの行動履歴や アイテムの閲覧履歴を元に 似たユーザ同士や似たアイテム同士を利用  

詳細は [7章](#7章--映画の推薦システムをつくる) 参照



#### 2.5.2  異常検知

クレジットカードの不正決済やDoS攻撃による不正検知など 異常を検知するデータマイニング手法  

外れ値検知(Outilier Detection)とも言う 詳細は [3章](#3章--学習結果を評価しよう) 参照  



#### 2.5.3  頻出パターンマイニング

データ中に高頻度に出現するパターンを抽出する  

「ビールと紙おむつがよく変われる」という例え話のように 購買情報から頻出パターンを抽出  



#### 2.5.4  強化学習

経験を元に試行錯誤し ある目的にために  

この場合こうすれば良い といったような最適な行動指針を獲得する方法  

例えば 囲碁・将棋のように「ゲームに勝つ」というメタな目的に向かって何かしらの行動をとり  

その行動結果の良し悪しを元に次の手を決める  

自動運転 や ゲームAIなどの分野で注目を集めるなど重要なジャンルだが 本書では扱わない  



---

### 2.6  この章のまとめ
どのアルゴリズムを選ぶかは重要  

データの傾向を見ながらできるだけ色々なアルゴリズムを試すのが良い  



## 3章  学習結果を評価しよう

### 3.1  分類の評価
#### 3.1.1  正解率を使えば良いのか？
#### 3.1.2  データ数の偏りを考慮する適合率と再現率
#### 3.1.3  F値でバランスの良い性能を見る
#### 3.1.4  混同行列を知る
#### 3.1.5  多クラス分類の平均のとり方: マイクロ平均，マクロ平均
#### 3.1.6  分類モデルを比較する
### 3.2  回帰の評価
#### 3.2.1  平均二乗誤差
#### 3.2.2  決定係数
### 3.3  機械学習を組み込んだシステムのA/Bテスト
### 3.4  この章のまとめ
## 4章  システムに機械学習を組み込む
### 4.1  システムに機械学習を含める流れ
### 4.2  システム設計
#### 4.2.1  混乱しやすい「バッチ処理」と「バッチ学習」
#### 4.2.2  バッチ処理で学習＋予測結果をWebアプリケーションで直接算出する（リアルタイム処理で予測）
#### 4.2.3  バッチ処理で学習＋予測結果をAPI経由で利用する（リアルタイム処理で予測）
#### 4.2.4  バッチ処理で学習＋予測結果をDB経由で利用する（バッチ処理で予測）
#### 4.2.5  リアルタイム処理で学習をする
#### 4.2.6  各パターンのまとめ
### 4.3  ログ設計
#### 4.3.1  特徴量や教師データに使いうる情報
#### 4.3.2  ログを保持する場所
#### 4.3.3  ログを設計する上での注意点
### 4.4  この章のまとめ
## 5章  学習のためのリソースを収集しよう
### 5.1  学習のためのリソースの取得方法
### 5.2  公開されたデータセットやモデルを活用する
### 5.3  開発者自身が教師データを作る
### 5.4  同僚や友人などにデータ入力してもらう
### 5.5  クラウドソーシングを活用する
### 5.6  サービスに組み込み，ユーザに入力してもらう
### 5.7  この章のまとめ
## 6章  効果検証
### 6.1  効果検証の概要
#### 6.1.1  効果検証までの道程
#### 6.1.2  オフラインで検証しにくいポイント
### 6.2  仮説検定の枠組み
#### 6.2.1  コインは歪んでいるか
#### 6.2.2  二群の母比率の差の検定
#### 6.2.3  偽陽性と偽陰性
### 6.3  仮説検定の注意点
#### 6.3.1  繰り返し検定をしてしまう
#### 6.3.2  有意差とビジネスインパクト
#### 6.3.3  複数の検定を同時に行う
### 6.4  因果効果の推定
#### 6.4.1  ルービンの因果モデル
#### 6.4.2  セレクションバイアス
#### 6.4.3  ランダム化比較試験
#### 6.4.4  過去との比較は難しい
### 6.5  A/Bテスト
#### 6.5.1  2群の抽出と標本サイズ
#### 6.5.2  A/Aテストによる均質さの確認
#### 6.5.3  A/Bテストの仕組み作り
#### 6.5.4  テストの終了
### 6.6  この章のまとめ
## 第II部
## 7章  映画の推薦システムをつくる
### 7.1  シナリオ
#### 7.1.1  推薦システムとは
#### 7.1.2  応用シーン
### 7.2  推薦システムをもっと知ろう
#### 7.2.1  データの設計と取得
#### 7.2.2  明示的データと暗黙的データ
#### 7.2.3  推薦システムのアルゴリズム
#### 7.2.4  ユーザー間型協調フィルタリング
#### 7.2.5  アイテム間型協調フィルタリング
#### 7.2.6  モデルベース協調フィルタリング
#### 7.2.7  内容ベースフィルタリング
#### 7.2.8  協調フィルタリングと内容ベースフィルタリングの得手・不得手
#### 7.2.9  評価尺度
### 7.3  MovieLensのデータの傾向を見る
### 7.4  推薦システムの実装
#### 7.4.1  Factorization Machineを使った推薦
#### 7.4.2  いよいよFactorizatoin Machineで学習する
#### 7.4.3  ユーザーと映画以外のコンテキストも加える
### 7.5  この章のまとめ
## 8章  Kickstarterの分析，機械学習を使わないという選択肢
### 8.1  KickstarterのAPIを調査する
### 8.2  Kickstarterのクローラを作成する
### 8.3  JSONデータをCSVに変換する
### 8.4  Excelで軽く眺めてみる
### 8.5  ピボットテーブルでいろいろと眺めてみる
### 8.6  達成したのにキャンセルされたプロジェクトを見てみる
### 8.7  国別に見てみる
### 8.8  レポートを作る
### 8.9  今後行いたいこと
### 8.10  おわりに
## 9章  Uplift Modelingによるマーケティング資源の効率化
### 9.1  Uplift Modelingの四象限のセグメント
### 9.2  A/Bテストの拡張を通じたUplift Modelingの概要
### 9.3  Uplift Modelingのためのデータセット生成
### 9.4  2つの予測モデルを利用したUplift Modeling
### 9.5  Uplift Modellingの評価方法，AUUC
### 9.6  実践的な問題での活用
### 9.7  Uplift Modelingを本番投入するには
### 9.8  この章のまとめ
