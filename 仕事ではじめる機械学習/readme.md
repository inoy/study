# 仕事ではじめる機械学習
仕事ではじめる機械学習のノート  
https://www.oreilly.co.jp/books/9784873118215/  

---
# 目次
<!-- TOC depthFrom:1 depthTo:6 withLinks:1 updateOnSave:1 orderedList:0 -->

- [仕事ではじめる機械学習](#仕事ではじめる機械学習)
- [目次](#目次)
	- [1章  機械学習プロジェクトのはじめ方](#1章--機械学習プロジェクトのはじめ方)
		- [1.1  機械学習はどのように使われるのか](#11--機械学習はどのように使われるのか)
		- [1.2  機械学習プロジェクトの流れ](#12--機械学習プロジェクトの流れ)
			- [1.2.1  問題を定式化する](#121--問題を定式化する)
			- [1.2.2  機械学習をしなくて良い方法を考える](#122--機械学習をしなくて良い方法を考える)
			- [1.2.3  システム設計を考える](#123--システム設計を考える)
			- [1.2.4  アルゴリズムを選定する](#124--アルゴリズムを選定する)
			- [1.2.5  特徴量，教師データとログの設計をする](#125--特徴量教師データとログの設計をする)
			- [1.2.6  前処理をする](#126--前処理をする)
			- [1.2.7  学習・パラメータチューニング](#127--学習パラメータチューニング)
			- [1.2.8  システムに組み込む](#128--システムに組み込む)
		- [1.3  実システムにおける機械学習の問題点への対処方法](#13--実システムにおける機械学習の問題点への対処方法)
			- [1.3.1  人手でゴールドスタンダードを用意して，予測性能のモニタリングをする](#131--人手でゴールドスタンダードを用意して予測性能のモニタリングをする)
			- [1.3.2  予測モデルをモジュール化をしてアルゴリズムのA/Bテストができるようにする](#132--予測モデルをモジュール化をしてアルゴリズムのabテストができるようにする)
			- [1.3.3  モデルのバージョン管理をして，いつでも切り戻し可能にする](#133--モデルのバージョン管理をしていつでも切り戻し可能にする)
			- [1.3.4  データ処理のパイプラインごと保存する](#134--データ処理のパイプラインごと保存する)
			- [1.3.5  開発/本番環境の言語/フレームワークは揃える](#135--開発本番環境の言語フレームワークは揃える)
		- [1.4  機械学習を含めたシステムを成功させるには](#14--機械学習を含めたシステムを成功させるには)
		- [1.5  この章のまとめ](#15--この章のまとめ)
	- [2章  機械学習で何ができる？](#2章--機械学習で何ができる)
		- [2.1  どのアルゴリズムを選ぶべきか？](#21--どのアルゴリズムを選ぶべきか)
		- [2.2  分類](#22--分類)
			- [2.2.1  パーセプトロン](#221--パーセプトロン)
			- [2.2.2  ロジスティック回帰](#222--ロジスティック回帰)
			- [2.2.3  SVM](#223--svm)
			- [2.2.4  ニューラルネットワーク](#224--ニューラルネットワーク)
			- [2.2.5  k-NN](#225--k-nn)
			- [2.2.6  決定木，ランダムフォレスト，GBDT](#226--決定木ランダムフォレストgbdt)
		- [2.3  回帰](#23--回帰)
			- [2.3.1  線形回帰の仕組み](#231--線形回帰の仕組み)
		- [2.4  クラスタリング・次元削減](#24--クラスタリング次元削減)
			- [2.4.1  クラスタリング](#241--クラスタリング)
			- [2.4.2  次元削減](#242--次元削減)
		- [2.5  その他](#25--その他)
			- [2.5.1  推薦](#251--推薦)
			- [2.5.2  異常検知](#252--異常検知)
			- [2.5.3  頻出パターンマイニング](#253--頻出パターンマイニング)
			- [2.5.4  強化学習](#254--強化学習)
		- [2.6  この章のまとめ](#26--この章のまとめ)
	- [3章  学習結果を評価しよう](#3章--学習結果を評価しよう)
		- [3.1  分類の評価](#31--分類の評価)
			- [3.1.1  正解率を使えば良いのか？](#311--正解率を使えば良いのか)
			- [3.1.2  データ数の偏りを考慮する適合率と再現率](#312--データ数の偏りを考慮する適合率と再現率)
			- [3.1.3  F値でバランスの良い性能を見る](#313--f値でバランスの良い性能を見る)
			- [3.1.4  混同行列を知る](#314--混同行列を知る)
			- [3.1.5  多クラス分類の平均のとり方: マイクロ平均，マクロ平均](#315--多クラス分類の平均のとり方-マイクロ平均マクロ平均)
			- [3.1.6  分類モデルを比較する](#316--分類モデルを比較する)
		- [3.2  回帰の評価](#32--回帰の評価)
			- [3.2.1  平均二乗誤差](#321--平均二乗誤差)
			- [3.2.2  決定係数](#322--決定係数)
		- [3.3  機械学習を組み込んだシステムのA/Bテスト](#33--機械学習を組み込んだシステムのabテスト)
		- [3.4  この章のまとめ](#34--この章のまとめ)
	- [4章  システムに機械学習を組み込む](#4章--システムに機械学習を組み込む)
		- [4.1  システムに機械学習を含める流れ](#41--システムに機械学習を含める流れ)
		- [4.2  システム設計](#42--システム設計)
			- [4.2.1  混乱しやすい「バッチ処理」と「バッチ学習」](#421--混乱しやすいバッチ処理とバッチ学習)
			- [4.2.2  バッチ処理で学習＋予測結果をWebアプリケーションで直接算出する（リアルタイム処理で予測）](#422--バッチ処理で学習予測結果をwebアプリケーションで直接算出するリアルタイム処理で予測)
			- [4.2.3  バッチ処理で学習＋予測結果をAPI経由で利用する（リアルタイム処理で予測）](#423--バッチ処理で学習予測結果をapi経由で利用するリアルタイム処理で予測)
			- [4.2.4  バッチ処理で学習＋予測結果をDB経由で利用する（バッチ処理で予測）](#424--バッチ処理で学習予測結果をdb経由で利用するバッチ処理で予測)
			- [4.2.5  リアルタイム処理で学習をする](#425--リアルタイム処理で学習をする)
			- [4.2.6  各パターンのまとめ](#426--各パターンのまとめ)
		- [4.3  ログ設計](#43--ログ設計)
			- [4.3.1  特徴量や教師データに使いうる情報](#431--特徴量や教師データに使いうる情報)
			- [4.3.2  ログを保持する場所](#432--ログを保持する場所)
			- [4.3.3  ログを設計する上での注意点](#433--ログを設計する上での注意点)
		- [4.4  この章のまとめ](#44--この章のまとめ)
	- [5章  学習のためのリソースを収集しよう](#5章--学習のためのリソースを収集しよう)
		- [5.1  学習のためのリソースの取得方法](#51--学習のためのリソースの取得方法)
		- [5.2  公開されたデータセットやモデルを活用する](#52--公開されたデータセットやモデルを活用する)
		- [5.3  開発者自身が教師データを作る](#53--開発者自身が教師データを作る)
		- [5.4  同僚や友人などにデータ入力してもらう](#54--同僚や友人などにデータ入力してもらう)
		- [5.5  クラウドソーシングを活用する](#55--クラウドソーシングを活用する)
		- [5.6  サービスに組み込み，ユーザに入力してもらう](#56--サービスに組み込みユーザに入力してもらう)
		- [5.7  この章のまとめ](#57--この章のまとめ)
	- [6章  効果検証](#6章--効果検証)
		- [6.1  効果検証の概要](#61--効果検証の概要)
			- [6.1.1  効果検証までの道程](#611--効果検証までの道程)
			- [6.1.2  オフラインで検証しにくいポイント](#612--オフラインで検証しにくいポイント)
		- [6.2  仮説検定の枠組み](#62--仮説検定の枠組み)
			- [6.2.1  コインは歪んでいるか](#621--コインは歪んでいるか)
			- [6.2.2  二群の母比率の差の検定](#622--二群の母比率の差の検定)
			- [6.2.3  偽陽性と偽陰性](#623--偽陽性と偽陰性)
		- [6.3  仮説検定の注意点](#63--仮説検定の注意点)
			- [6.3.1  繰り返し検定をしてしまう](#631--繰り返し検定をしてしまう)
			- [6.3.2  有意差とビジネスインパクト](#632--有意差とビジネスインパクト)
			- [6.3.3  複数の検定を同時に行う](#633--複数の検定を同時に行う)
		- [6.4  因果効果の推定](#64--因果効果の推定)
			- [6.4.1  ルービンの因果モデル](#641--ルービンの因果モデル)
			- [6.4.2  セレクションバイアス](#642--セレクションバイアス)
			- [6.4.3  ランダム化比較試験](#643--ランダム化比較試験)
			- [6.4.4  過去との比較は難しい](#644--過去との比較は難しい)
		- [6.5  A/Bテスト](#65--abテスト)
			- [6.5.1  2群の抽出と標本サイズ](#651--2群の抽出と標本サイズ)
			- [6.5.2  A/Aテストによる均質さの確認](#652--aaテストによる均質さの確認)
			- [6.5.3  A/Bテストの仕組み作り](#653--abテストの仕組み作り)
			- [6.5.4  テストの終了](#654--テストの終了)
		- [6.6  この章のまとめ](#66--この章のまとめ)
	- [第II部](#第ii部)
	- [7章  映画の推薦システムをつくる](#7章--映画の推薦システムをつくる)
		- [7.1  シナリオ](#71--シナリオ)
			- [7.1.1  推薦システムとは](#711--推薦システムとは)
			- [7.1.2  応用シーン](#712--応用シーン)
		- [7.2  推薦システムをもっと知ろう](#72--推薦システムをもっと知ろう)
			- [7.2.1  データの設計と取得](#721--データの設計と取得)
			- [7.2.2  明示的データと暗黙的データ](#722--明示的データと暗黙的データ)
			- [7.2.3  推薦システムのアルゴリズム](#723--推薦システムのアルゴリズム)
			- [7.2.4  ユーザー間型協調フィルタリング](#724--ユーザー間型協調フィルタリング)
			- [7.2.5  アイテム間型協調フィルタリング](#725--アイテム間型協調フィルタリング)
			- [7.2.6  モデルベース協調フィルタリング](#726--モデルベース協調フィルタリング)
			- [7.2.7  内容ベースフィルタリング](#727--内容ベースフィルタリング)
			- [7.2.8  協調フィルタリングと内容ベースフィルタリングの得手・不得手](#728--協調フィルタリングと内容ベースフィルタリングの得手不得手)
			- [7.2.9  評価尺度](#729--評価尺度)
		- [7.3  MovieLensのデータの傾向を見る](#73--movielensのデータの傾向を見る)
		- [7.4  推薦システムの実装](#74--推薦システムの実装)
			- [7.4.1  Factorization Machineを使った推薦](#741--factorization-machineを使った推薦)
			- [7.4.2  いよいよFactorizatoin Machineで学習する](#742--いよいよfactorizatoin-machineで学習する)
			- [7.4.3  ユーザーと映画以外のコンテキストも加える](#743--ユーザーと映画以外のコンテキストも加える)
		- [7.5  この章のまとめ](#75--この章のまとめ)
	- [8章  Kickstarterの分析，機械学習を使わないという選択肢](#8章--kickstarterの分析機械学習を使わないという選択肢)
		- [8.1  KickstarterのAPIを調査する](#81--kickstarterのapiを調査する)
		- [8.2  Kickstarterのクローラを作成する](#82--kickstarterのクローラを作成する)
		- [8.3  JSONデータをCSVに変換する](#83--jsonデータをcsvに変換する)
		- [8.4  Excelで軽く眺めてみる](#84--excelで軽く眺めてみる)
		- [8.5  ピボットテーブルでいろいろと眺めてみる](#85--ピボットテーブルでいろいろと眺めてみる)
		- [8.6  達成したのにキャンセルされたプロジェクトを見てみる](#86--達成したのにキャンセルされたプロジェクトを見てみる)
		- [8.7  国別に見てみる](#87--国別に見てみる)
		- [8.8  レポートを作る](#88--レポートを作る)
		- [8.9  今後行いたいこと](#89--今後行いたいこと)
		- [8.10  おわりに](#810--おわりに)
	- [9章  Uplift Modelingによるマーケティング資源の効率化](#9章--uplift-modelingによるマーケティング資源の効率化)
		- [9.1  Uplift Modelingの四象限のセグメント](#91--uplift-modelingの四象限のセグメント)
		- [9.2  A/Bテストの拡張を通じたUplift Modelingの概要](#92--abテストの拡張を通じたuplift-modelingの概要)
		- [9.3  Uplift Modelingのためのデータセット生成](#93--uplift-modelingのためのデータセット生成)
		- [9.4  2つの予測モデルを利用したUplift Modeling](#94--2つの予測モデルを利用したuplift-modeling)
		- [9.5  Uplift Modellingの評価方法，AUUC](#95--uplift-modellingの評価方法auuc)
		- [9.6  実践的な問題での活用](#96--実践的な問題での活用)
		- [9.7  Uplift Modelingを本番投入するには](#97--uplift-modelingを本番投入するには)
		- [9.8  この章のまとめ](#98--この章のまとめ)

<!-- /TOC -->

## 1章  機械学習プロジェクトのはじめ方
機械学習の概要，プロジェクトの流れ，機械学習特有の問題，チームづくりについて紹介  
Pythonの機械学習ライブラリscikit-learnを使うことを前提に説明  

### 1.1  機械学習はどのように使われるのか
skip  

### 1.2  機械学習プロジェクトの流れ
以下の流れで進めると良い  

Ⅰ. 解きたい課題を機械学習で解ける問題設定に落としこむ  

　1. 問題を定式化する  
　2. 機械学習をしないで良い方法を考える  

Ⅱ. 解くための 道具選び と 前処理  

　3. システム設計を考える  
　4. アルゴリズムを選定する  
　5. 特徴量，教師データとログの設計をする  
　6. 前処理をする  

Ⅲ. モデルの作成  

　7. 学習・パラメータチューニング  

Ⅳ. サービスへの組み込み  

　8. システムに組み込む  



機械学習で 何ができて何ができなさそうか 判断できるようになるためには  
「機械学習でこういう課題を解決した」という事例を見たとき 以下を意識して調べると良い  

- どういったアルゴリズムで解決したか  
- どのようなデータをFeatureにしているか  
- 機会学習をどのように組み込んでいるか  

#### 1.2.1  問題を定式化する
目的を明確にし 仮説を立て アクション可能なレベルにする  

例えば 目的「生産コストを減らす」から (仮説「不良が減ればコストが減る」)  
アクション可能なレベル「どこで不良が起こっているか特定するために機械学習を使う」  

この過程で ビジネス上の指標 KPI(Key Performance Indicator)を仮で良いので決める  

#### 1.2.2  機械学習をしなくて良い方法を考える
ビジネスで機械学習を利用する際に満たすべき条件  
- 大量データに対し 高速に安定して判断を求める必要がある  
- 予測結果に 一定の間違いが含まれることが許容できる  

この条件を満たしたうえで まずはMVP(\*)を作り 立てた仮説の筋が良いか悪いかを確認すべき  
　\* MVP: Minimu Viable Product 最低限の顧客価値を生み出す最小プロダクト

MVPを作る際に有用なOSS: Apache Solr や Elasticsearch の More Like This 機能

#### 1.2.3  システム設計を考える
設計で重要なポイントは以下  
- 予測結果をどういう形で利用するのか -> 詳細は [4章 システムに機械学習を組み込む](#4章--システムに機械学習を組み込む) 参照  
- 予測誤りをどこで吸収するのか  

この段階で 撤退ライン(例: 2ヵ月で90%の予測性能を達成する) を決めておくと良い  
予測性能の決め方は 3章 学習結果を評価しよう を参照  

#### 1.2.4  アルゴリズムを選定する
アルゴリズム選定の指針の詳細は [2章 機械学習で何ができる？](#2章--機械学習で何ができる) を参照  

#### 1.2.5  特徴量，教師データとログの設計をする
特徴量(Feature)の設計 の考え方  
- ビジネスドメインの知識を持った人と協力して 何がその現象に影響を与えそうか確認する  
	例: タービンの不具合検出に 過去の経験を元にハンマーで叩いた音をFeatureとした
- 後から不要なデータを削ることはできるけど 必要なデータを遡って取得することはできない  
- 晴れ, 曇りのようなFeatureはカテゴリカル変数と言い  
	ダミー変数(数値データ)に変換して処理する  
	scikit-learnでダミー変数への変換はLabelEncoder, OneHotEncoder クラスが利用可能  

教師データを用意するために  
- 質の良い正解ラベルをどのように取得するかが重要  
	正解ラベル収集の詳細は [5章 学習のためのリソースを収集しよう](#5章--学習のためのリソースを収集しよう) を参照  
- 元となる情報をWebアプリのログから取得することが よく行われる  
	Featureを抽出するためのログ設計の詳細については [4.3  ログ設計](#43--ログ設計) 参照  

#### 1.2.6  前処理をする
- テキスト形式のデータ  
	単語に分割して頻度を変えたり 低頻度を除去したり ダミー変数に変換したり
- 数値データ  
	欠損値のデータ処理をしたり 異常値を除外したり 正規化したり  

ここに多くの時間を取られる

#### 1.2.7  学習・パラメータチューニング
機械学習のパラメタを試行錯誤しながら変えて より良い結果がでるパラメタを探索する  

いきなり予測性能99.9%のような高い性能が出た場合  
過学習(Overfitting) や DataLeakage が発生していないか疑うべき  

性能改善には 誤判定した予測結果から エラー分析(何が誤りの原因か, 共通項はないか)する  

#### 1.2.8  システムに組み込む
機械学習のロジックをシステムに組み込んだら  
予測性能 と それに伴うビジネスインパクト(KPI) をモニタリングする  

入力の傾向が変わり(トレンドが変わり) 同じ予測モデルを使い続けていると  
予測性能が劣化する場合がある そのときは [手順5](#125--特徴量教師データとログの設計をする)～[7](#127--学習パラメータチューニング) に立ち戻って改善する  

改善し続けるため KPIをトラックし易いよう  
ダッシュボードを作ったり 異常時にアラートを飛ばす仕組みを作る  

### 1.3  実システムにおける機械学習の問題点への対処方法
機械学習システムを継続して 改善/メンテナンス するために重要なポイント について
// この章 全体的にちゃんと理解できてない感ある  

#### 1.3.1  人手でゴールドスタンダードを用意して，予測性能のモニタリングをする
定期的に 人工データセット(x, y)作成 -> 予測性能の測定 を実施してモニタリングする  

これにより 予測モデルの定期的評価(テストでき) や トレンド変化による劣化に気付ける

モニタリング用のデータセットは同じものを使い続けるのか(多分 違う)  
適当に都度作り直すのか どうやって作る?(取ってくる?)のか分からない  

#### 1.3.2  予測モデルをモジュール化をしてアルゴリズムのA/Bテストができるようにする
機械学習システムの全体像が理解できていないため  
どこをモジュール化すべきと言ってくれているのか具体的に理解できない  
各前処理 と 予測モデル生成の処理は分けるとして 他がよく分からない  

#### 1.3.3  モデルのバージョン管理をして，いつでも切り戻し可能にする
ソースコード, モデル, データ の3つをバージョン管理できるのが理想  

モデル(関数?)は どのソースコード, データから生成したかドキュメント化すると良い  

#### 1.3.4  データ処理のパイプラインごと保存する
機械学習システムのデータ パイプラインは以下  
`Originalデータ -> 前処理 -> 予測モデル生成 -> 予測値の取得`  
[1.3.3](#133--モデルのバージョン管理をしていつでも切り戻し可能にする)で指すソースコードには これらすべての処理を含めましょう という話？  

[TODO] scikit-learnに以下の機能があるらしいので この辺りを勉強すれば理解できるかも  
> 更に前処理やアルゴリズムのパイプラインを作成し、性能が最も良い組み合わせを保存することができます

#### 1.3.5  開発/本番環境の言語/フレームワークは揃える
これも見出しの通り  

マイクロサービス的なアーキ(REST APIでやり取り)に出来るなら必ずしも揃えないのもあり  
予測モデル開発 と アプリ開発で それぞれ得意な言語・フレームワークを使う  

### 1.4  機械学習を含めたシステムを成功させるには
成功には 以下の4者(兼務もあり)がチームに必要
- プロダクトに関するドメイン知識を持った人  
	解くべき課題は何か プロダクトのどこに機械学習の手法が必要か を考える  
	また Feature選定や データ収集の方法 を考える
- 統計や機会学習に明るい人  
	この本で説明してくれていることができる人  
- データ分析基盤を作れるエンジニアリング能力のある人  
	= データエンジニア: データを活用できるようにする分析基盤を作る人  
- 失敗しても構わないとリスクを取ってくれる責任者  
	機械学習のリスクを認識・理解したうえで お金取ってくれる/来てくれる 人  

### 1.5  この章のまとめ
機械学習プロジェクトの進め方とそのポイント まとめ  
- 解くべき問題の仮説を立て MVPを作りコンセプトの検証を最優先する [1.2.2](#122--機械学習をしなくて良い方法を考える)  
- 機械学習をしないことを恐れない [1.2.2](#122--機械学習をしなくて良い方法を考える)  
- 機械学習に適している問題設定かを見極める [1.2.2](#122--機械学習をしなくて良い方法を考える)  
- 予測性能とKPIの両方のモニタリングし、継続して改善を続ける [1.2.8](#128--システムに組み込む)  

## 2章  機械学習で何ができる？
できることを 分類, 回帰, クラスタリング, 次元削減, その他 に分けて解説  
まずは アルゴリズムをどう選ぶべきかについて  

### 2.1  どのアルゴリズムを選ぶべきか？
どのアルゴリズムを使えば良いか考えるには アルゴリズムの特徴を知る必要がある  
- 分類: 教師あり学習 離散データ(クラス)を予測  
- 回帰: 教師あり学習 連続値を予測  
- クラスタリング: 教師なし学習 グルーピング
- 次元削減: 教師なし学習 グラフ化や計算量削減のために高次元データを低次元にマッピング  
- その他 (これはアルゴリズム?)
	- 推薦: ユーザが好みそうなアイテムや 類似アイテムを提示  
	- 異常検知: 不審なアクセスなど 負担とは違う挙動を検知
	- 頻出パターンマイニング: データ中に高頻度で出現するパターンを抽出  
	- 強化学習: 囲碁, 将棋など 局所的には正解が不明瞭な環境でとるべき行動の方針を学習  

アルゴリズムの選択基準(本に簡略・日本語化してくれている図があるけど ここには載せない)   

<img src="https://scikit-learn.org/stable/_static/ml_map.png" width=50%>  
https://scikit-learn.org/stable/_static/ml_map.png  

アルゴリズムの選択では以下がポイント  
データセット量, 予測対象が離散データか, データセットにラベルが存在するか  

### 2.2  分類
教師あり学習 予測対象はカテゴリなどの離散値(クラス)  
例えば メールがスパムかどうか 画像に何が映っているか  
クラス数が2なら二値分類 3以上なら多値分類/多クラス分類  

以降 本節では 分類のアルゴリズムを紹介  

書籍内では アルゴリズムを図/グラフで直感的に理解できるようにしてくれているので  
忘れたときは図/グラフを見ると思い出しやすいと思う  

#### 2.2.1  パーセプトロン
`Feature と 学習した重み の積和`(出力値)が0以上ならクラス1 0未満ならクラス2に分類する  
活性化関数(出力値を非線形変換する関数)はステップ関数(入力値を+1/-1(0)にする関数)  
損失関数は $$max(0, -y \times h_{Θ}(x))$$ というヒンジ損失  

パーセプトロンの特徴  
- オンライン学習(≠バッチ学習)で学習する  
  つまり データを1つずつ入力して最適化する(≠全部を入れて最適化する) 詳細は[4.2.1](#421--混乱しやすいバッチ処理とバッチ学習)参照  
- 予測性能はそこそこで 学習は速い
- 過学習しやすい  
  伝統的なパーセプトロンには過学習を抑制する仕組み(正則化項の導入)が無いため  
- 線形分離可能な問題のみ解ける  

#### 2.2.2  ロジスティック回帰
パーセプトロンとの違い
- 活性化関数 シグモイド関数  
  詳細は[CourseraのMachineLearningノート](https://github.com/ysk-in/study/tree/master/MachineLearning/week03/02_HypothesisRepresentation)参照
- CostFunction $$-\sum_{i=1}^{m}y^{(i)}\log(h_{Θ}(x^{(i)})) + (1-y^{(i)})\log(1-h_{Θ}(x^{(i)}))$$
  詳細は[CourseraのMachineLearningノート](https://github.com/ysk-in/study/tree/master/MachineLearning/week03/05_SimplifiedCostFunctionAndGradientDescent)参照
- 正則化項がある  
  詳細は[CourseraのMachineLearningノート](https://github.com/ysk-in/study/tree/master/MachineLearning/week03/11_RegularizedLogisticRegression)参照  

ロジスティック回帰の特徴  
- クラスに所属する確率値が出せる(活性関数がシグモイド関数)  
- オンライン学習でもバッチ学習でも可能  
- 予測性能はまずまず 学習速度は速い  
- 過学習が防げる(正則化項がある)  
- 線形分離可能な問題のみ解ける  

#### 2.2.3  SVM
パーセプトロンを拡張したアルゴリズム 分類では非常に良く利用される  

損失関数はパーセプトロンと同じヒンジ損失だが ぎりぎり正解にもペナルティを与える

SVMの特徴  
- マージン最大化をすることで なめらかな超平面を学習できる  
  超平面をどう引けば サポートベクトル(2クラスそれぞれ最も近いデータ)までの距離を  
  最大化できるかを考える これにより既知データに対しあそびが生まれ 過学習が抑止できる  
- カーネル(Kernel)と呼ばれる方法を使い 非線形なデータを分離できる  
  線形カーネル: 直線で分離  
  RBFカーネル: 非線形に分離
  特徴量を疑似的に追加しデータを高次元にすることで 線形分離可能にする   
- 線形カーネルなら次元数の多い疎なデータも学習可能  
  疎なデータとはFeatureのほとんどが0でたまに値が入っているデータのこと  
  例えば テキストデータから単語の頻度をデータにするとき 対応する単語の種類を10,000など多くすると 疎なデータになる  
  逆にほとんどが0以外のデータは密なデータと言う 小さくリサイズした画像などが該当する  
- バッチ学習でもオンライン学習でも可能  

#### 2.2.4  ニューラルネットワーク
多層パーセプトロンとも呼ばれる  

活性化関数には近年ではReLU(Rectified Linear Unit)がよく使われる  

ニューラルネットワークの特徴  
- 非線形なデータを分離できる  
- 学習に時間がかかる  
- パラメータ数が多いので 過学習しやすい  
- 重みの初期値に依存して 局所最適解にはまりやすい  

#### 2.2.5  k-NN
k-NN(k近傍法, k-Nearest Neighbor Method)  

データのクラスを 近くのk個のデータが属するクラスの多数決で決める  

k-NNの特徴  
- データを1つずつ逐次学習する  
- 基本的に全データとの距離計算をする必要があるため 予測計算に時間がかかる  
- kの数によるがそこそこの予測性能  
- Featureのスケールが大きく違うと上手く学習できないため 正規化が必要  

#### 2.2.6  決定木，ランダムフォレスト，GBDT
##### 決定木
ツリー型のアルゴリズムの代表 決定木(Decision Tree)  
その発展形 ランダムフォレスト と Gradient Boosted  Decision Tree(GBDT)  

決定木の特徴  
- 学習したモデルを人間が見て解釈しやすい  
  学習結果としてIF-THENルールが得られるため  
- 入力データの正規化がいらない  
- カテゴリ変数や欠損値などを入力しても内部で処理してくれる  
- 特定の条件下で過学習しやすい傾向にある  
  データを条件分岐で分けて性質上  
  木の深さが深くなると学習に使えるデータ数が少なくなるため 過学習しやすい  
  これは枝刈り(剪定, Pruning)したり Feature減らしたり次元削減したりである程度は防げる  
- 非線形分離可能だが 線形分離可能な問題は不得意  
  領域の分割を繰り返し決定境界をつくるため 直線にならない  
- クラスごとのデータ数に偏りのあるデータは不得意  
- データの小さな変化に対して結果が大きく変わりやすい  
- 予測性能はまずまず  
- バッチ学習でしか学習できない  

##### ランダムフォレスト
利用するFeatureの組み合わせをいくつか用意し 性能が良い学習器の予測結果を多数決で統合  

複数の木を独立して学習するため 並列して学習できる  

##### GBDT
直列的に浅い木を学習していく勾配ブースティング法を使うアルゴリズム  
予測値と実測値のズレを目的変数として考慮し 弱点を補強しながら学習  

- 直列で学習するため時間がかかる  
  ただ 高速なライブラリ(XGBoostやLightGBM)の登場もあり 大規模データでも処理し易い
- パラメータ数が多いためチューニングにコストがかかる  
- ランダムフォレストより高い予測性能が得られる  

ランダムフォレストやGBDTのように 複数の学習結果を組み合わせる手法をアンサンブル学習と言う  

### 2.3  回帰
教師あり学習 入力データから連続値を予測する  

例えば 都市の電力消費量 や Webサイトのアクセス数  

各アルゴリズムの おおよその傾向  
- 線形回帰(Linear Regression): データを直線で近似するもの  
- 多項式回帰(Polynomial Regression): 曲線で近似したもの  
- Lasso回帰, Ridge回帰, Elastic Net  
  線形回帰に以下を正則化項として追加したもの  
  Ridge回帰は学習した重みの2乗を(L2正則化)  
  Lasso回帰は学習した重みの絶対値を(L1正則化)  
  Elastic Netはその両方
- 回帰木(Regression Tree)
  決定機ベース 非線形なデータに対してフィッティングできる  
- SVR(Support Vector Regression)  
  SVMベース 非線形なデータに対してもフィッティングできる  
線形なデータだと分かっているときは 線形/Lasso/Ridge 回帰 または Elastic Netを用い  

それでも上手くいかない場合は 回帰木やSVRなど 非線形な回帰を用いるのが良い  

#### 2.3.1  線形回帰の仕組み
skip Courseraの内容と重複のため  

### 2.4  クラスタリング・次元削減
クラスタリングと次元削減について説明  

#### 2.4.1  クラスタリング
教師なし学習 主にデータの傾向をつかむために使われる 手法として例えば 以下がある  
- 階層的クラスタリング(Hierarchical Clustering): 似ている組み合わせを順番にまとめていく  
- k-means: 距離の近いもの同士をk個のグループに分割する

#### 2.4.2  次元削減
高次元のデータからできるだけ情報を保持しながら低次元のデータへ変換する  

例えば100次元データがあるとき これをを2次元にしてグラフ表現してみて 特徴を見てみる  
手法として 主成分分析(PCA, Principal Component Analysis) や t-SNE(特に可視化に有効) がある  

### 2.5  その他
その他　機械学習 や データマイニング関連でよく取り組まれるトピック について  

#### 2.5.1  推薦
ユーザが好みそうなアイテム や 類似するアイテムを提示する  

ユーザの行動履歴や アイテムの閲覧履歴を元に 似たユーザ同士や似たアイテム同士を利用  
詳細は [7章](#7章--映画の推薦システムをつくる) 参照

#### 2.5.2  異常検知
クレジットカードの不正決済やDoS攻撃による不正検知など 異常を検知するデータマイニング手法  

外れ値検知(Outilier Detection)とも言う 詳細は [3章](#3章--学習結果を評価しよう) 参照  

#### 2.5.3  頻出パターンマイニング
データ中に高頻度に出現するパターンを抽出する  

「ビールと紙おむつがよく変われる」という例え話のように 購買情報から頻出パターンを抽出  

#### 2.5.4  強化学習
経験を元に試行錯誤し ある目的にために  
この場合こうすれば良い といったような最適な行動指針を獲得する方法  

例えば 囲碁・将棋のように「ゲームに勝つ」というメタな目的に向かって何かしらの行動をとり  
その行動結果の良し悪しを元に次の手を決める  

自動運転 や ゲームAIなどの分野で注目を集めるなど重要なジャンルだが 本書では扱わない  

### 2.6  この章のまとめ
どのアルゴリズムを選ぶかは重要  

データの傾向を見ながらできるだけ色々なアルゴリズムを試すのが良い  

## 3章  学習結果を評価しよう
機械学習の結果を評価する方法について  

### 3.1  分類の評価
スパム分類の例を考えながら以下4つの指標について紹介  
- 正解率 (Accuracy)  
- 適合率 (Precision)  
- 再現率 (Recall)  
- F値 (F-measure)  

また これらを考えるうえで重要な3つの概念について説明  
- 混合行列 (Confusion Matrix)  
- マイクロ平均 (Micro-average)  
- マクロ平均 (Macro-average)  

#### 3.1.1  正解率を使えば良いのか？
分類タスクでは 正しく分類されたか否かで分類器の性能を見極める  

まずは一番シンプルな正解率 (Accuracy) について  
`正解率 = 正解した数 / 予測した全データ数`   

例えば スパム分類で 全100件のメールがあり うちスパムが60件含まれるとき  
すべてをスパムとする分類器があったとすると 正解率 (Accuracy) は60%  

分類問題の場合 一般的にはランダムで出力した結果が 性能の最低水準  
つまり 2値分類の場合は50% 3値分類の場合は33% 上記スパム分類は60%で良い数字に見えるが 
すべてスパムと予測しているためか適切に評価されている気がしない  

現実の問題では 分類するクラスそれぞれに偏りがあることが多く  
単純な正解率はあまり意味を成さないことがほとんど  

#### 3.1.2  データ数の偏りを考慮する適合率と再現率
正解率があまり意味を成さないなら 何を使えば良いか  

適合率 (Precision) と 再現率 (Recall) の考え方 について  
適合率は精度とも呼ばれ 出力結果がどの程度正解していたかを表す指標  
再現率は 出力結果が 実際の正解全体のうち どのくらいの割合をカバーしていたかを表す指標  

例えばスパム分類で スパムと予測したメールが80件で 実際のスパムメールが55件だった場合  
`適合率 = 55 / 80 = 0.6875 ≒ 0.69`となり ランダムの0.5よりは良いが あまり高いとは言えない  

再現率は 今回 全データに含まれるスパムの数60件 スパムであると予測した正解55件 なので  
`再現率 = 55 / 60 = 0.916 ≒ 0.92`となり 比較的高い数字となる  

再現率の方が1に近いであることから 分類は「再現率重視」である と評価する  
適合率 と 再現率 はトレードオフの関係で 問題設定によってどちらを重視するかは異なる  

見逃しが多くても より正確な予測をしたい場合には 適合率を重視する  
スパム分類で言えば 重要なメールがスパムと誤判定されるより  
たまにスパムがすり抜けても構わないから スパムと予測したものが確実にスパムである方が 安心できる  

一方 誤りが多少多くても抜け漏れを少なくしたい場合には 再現率を重視する  
例えば 発生件数の少ない病気の検診で 病気と誤判定するケースが多少あっても 再検査すれば良いという考え方  

#### 3.1.3  F値でバランスの良い性能を見る
こうしたトレードオフがあることを踏まえたうえで  
分類器の比較に使われるのがF値 (F-measure)と呼ばれる 適合率と再現率の調和平均  
`F値 = 2 / (1 / 適合率 + 1 / 再現率) = 2 / (1 / 0.69 + 1 / 0.92) ≒ 0.79`  

再現率と適合率のバランスが良ければF値が高くなる = F値が高いとは 2つの指標のバランスが良い  

#### 3.1.4  混同行列を知る
続いて 混合行列 (Confusion Matrix)について  

混合行列は2つの軸 1つは予測結果の軸 もう1つが実際の結果の軸 について Positive/Negative を考える  

例えば 先のスパム分類では以下の通り  
![confusion_matrix](3.1.4_table_ConfusionMatrix.png "ConfusionMatrix")  

この混同行列を元に 正解率 適合率 再現率 を再び計算してみると 以下の通り  
`正解率 = (TP + TN) / (TP + FP + TN + FN) = (55 + 15) / (55 + 5 + 25 +15) = 0.7`
`適合率 = TP / (TP + FP) = 55 / (55 + 25) ≒ 0.69`  
`再現率 = TP / (TP + FN) = 55 / (55 + 5) ≒ 0.92`  

scikit-learnでは confusion_matrix関数で混同行列の値が取得できる  

#### 3.1.5  多クラス分類の平均のとり方: マイクロ平均，マクロ平均
多クラス分類の場合 クラス全体の平均をとる方法が2種類(マイクロ平均 と マクロ平均)ある  

マイクロ平均は 全クラスの結果をフラットに評価 例えば適合率をマイクロ平均で求めるときは以下  
`適合率(マイクロ平均) = (TP1 + TP2 + TP3) / (TP1 + TP2 + TP3 + FP1 + FP2 + FP3)`  

マクロ平均は クラスごとに計算し 最終的な評価値は 合計を クラス数で割る方法  
`適合率(マクロ平均) = (適合率1 + 適合率2 + 適合率3) / 3`  

マイクロ平均はクラスをまたいだ全体のパフォーマンスの概要を知るのに向き  

クラスごとにデータ数の偏りがある場合は マクロ平均を用いた方が偏りの影響を考慮した評価ができる  

#### 3.1.6  分類モデルを比較する
モデル同士の性能を比較をする場合 データに偏りがある場合も多いためF値をもとにすることが多い  

実問題を解くときには 適合率/再現率 どちらを重視するか考えて チューニングするのが望ましい  
例えば 誤りが許されない問題の場合「適合率が0.9以上にならないモデルは採用しない」という 
最低ラインを決めて そのうえでF値が高くなるようにパラメータチューニングしてモデルを決めると良い  

F値以外にもROC曲線 や AUC などの評価値が使われることもあるらしい(詳しくは扱わない)  

分類の性能は ビジネスに応用するうえでの品質を保つための最低基準だと考えるべき  
学習モデルの性能が高いことと ビジネスゴールを満たすことは別問題  
そのモデルで何を実現したかったか考える癖をつけると良い  
最終的なゴールとしての数値を満たせるかどうかを観測し 継続的に改善できる仕組みが必要  

### 3.2  回帰の評価

回帰は電力消費量や価格など，連続値を予測する問題。回帰の評価手法について扱う。  


#### 3.2.1  平均二乗誤差

回帰の評価で主に使われる手法，平均二乗誤差(Root Mean Squared Error, RMSE)について。数式は以下。  
$RMSE = \frac{\sqrt{\sum_{i}(予測値_{i} - 実測値_{i})^{2}}}{N} $   



scikit-learnではmean_squared_error関数が用意されている。  

```scikit-learn
rms = sqrt(mean_squared_error(y_actual, y_predicted))
```



回帰分析で，全データの平均値を出力するモデル(分類で言うところのランダム出力をする予測モデル)を考えるとき，その平均二乗誤差はデータのばらつき具合を示す標準偏差(Standard Deviation)となる。  
そのため，標準偏差 と 平均二乗誤差を比較することで，予測モデルの良し悪しを検討できる。  



#### 3.2.2  決定係数

評価指標，決定係数(Coefficient of Determination)について扱う。数式は以下の通り$$R^{2}$$で表現される。  
$$R^{2} = 1 - \frac{\sum_{i}(予測値_{i} - 実測値_{i})^2}{\sum_{i}(予測値_{i} - 実測値の平均値)^{2}}$$  



scikit-learnではr2_score関数が用意されている。  

```scikit-learn
r2 = r2_score(y, lr.predict(x))
```



決定係数は，常に平均値を出力する予測モデルに比べて，相対的にどのくらい性能が良いかを表す。  
1に近ければ近いほど良い性能であることを示し，0に近ければ性能が良くないことを示す。  



---

### 3.3  機械学習を組み込んだシステムのA/Bテスト

通常の機械学習で得られたモデルの評価より，少し範囲の広いお話。  
WebサービスではA/Bテストをよく行う。例えば，サービスの登録ボタンの色や文言を少しずつ変え，比較して，良かったパターンを採用するというようなテスト。  



A/Bテストのメリットは，一定数のユーザにパターンを出し分けることで，同一期間内に比較ができること。  
期間をずらして比較すると，季節などの影響が大きく意味をなさないことがあるため。  



機械学習のモデルを検証する際にも，オンラインで，モデルを適用しない場合のパフォーマンスや，複数のモデルによる予測結果を使った場合のパフォーマンスを比較するA/Bテストを行うことで，より最適なモデル選択ができる。  



オフラインで複数のアルゴリズムやパラメータチューニングを行なったモデルを用意し，A/Bテストで選別し，更に良いモデルを作成し，オフラインで検証，A/Bテストに投入，という検証サイクルを回すのが良い。  



### 3.4  この章のまとめ

本章では学習結果の評価方法について学んだ。  

分類の評価指標としては，混同行列を見ながら，どのクラスがどのくらいの性能があれば良いか考えるのが重要。  

回帰の評価指標としては，平均二乗誤差と決定係数について学んだ。  



機械学習の評価指標の良し悪しと，ビジネス上のゴールとしてのKPIの良し悪しは別。  
この2つの違いを常に意識することで，予測モデルの評価指標のみを追いかけないように気を付ける。  
オフラインで評価指標の目標を達成することは，機械学習を使ったビジネスのスタートラインに立つための最低条件。  



## 4章  システムに機械学習を組み込む

機械学習をシステムに組み込むにはどうすれば良いか。  
本章では，機械学習を組み込むシステム構成と教師データを獲得するためのログ収集方法について説明。  



### 4.1  システムに機械学習を含める流れ

システムに機械学習を適用する流れは，[1.2  機械学習プロジェクトの流れ](#12--機械学習プロジェクトの流れ)にある通り。  
本章では，「3. システム設計」「5. ログ設計」について扱う。  



### 4.2  システム設計

活用ケースが多い，教師あり学習について，システムに組み込む場合の構成について。  

分類や回帰などの教師あり学習の場合，学習と予測の2つのフェーズがある。  
更に学習のタイミングは，バッチ処理での学習とリアルタイム処理での学習の2種類がある。  

本節で，それぞれの場合のシステム構成とそのポイントについて学ぶ。  



#### 4.2.1  混乱しやすい「バッチ処理」と「バッチ学習」

まず，混乱しがちな用語について整理。 機会学習の文脈で「バッチ」というと「バッチ学習」のことを指す。  



バッチ処理 <-> リアルタイム処理  
バッチ学習(一括学習) <-> オンライン学習(逐次学習)



バッチ処理は，一括で何かを処理すること，またその処理そのものを指す。  
リアルタイム処理は，刻刻と流れてくるデータを逐次すること(とする)。  



一括学習と逐次学習とでは，データ保持の仕方が異なる。  
一括学習では，重み計算ですべての教師データを必要とするため，データ数増で必要メモリ量が増加する。  
逐次学習では，教師データを1つ与えて，都度重みを計算する。



〇 バッチ処理で一括学習: 一括処理で全教師データから重みを計算。  
〇 バッチ処理で逐次学習: 一括処理で教師データ1つずつ使って重みを計算。  
〇 リアルタイム処理で逐次学習: 刻々と流れてくるデータから重みを都度計算。  
× リアルタイム処理で一括学習: これは無い。  



実際に学習する際は，データを保持できない場合を除き，学習フェーズはバッチ処理が良い(試行錯誤し易い)。  
予測フェーズについては，学習フェーズでの最適化の方針や処理方法に関わらず，バッチ・リアルタイム 処理，どちらの予測も共に存在する。  



ここからは，学習フェーズをバッチ処理で行うパターンを3つ，リアルタイム処理で行うパターンを1つ見ていく。  

1. バッチ処理で学習 + 予測結果をWebアプリで直接算出(リアルタイム処理で予測)  
2. バッチ処理で学習 + 予測結果をAPI経由で利用(リアルタイム処理で予測)  
3. バッチ処理で学習 + 予測結果をDB経由で利用(バッチ処理で予測)  
4. リアルタイム処理で学習  



#### 4.2.2  バッチ処理で学習＋予測結果をWebアプリケーションで直接算出する（リアルタイム処理で予測）

バッチ処理で一括学習し，得られた予測モデルをWebアプリでリアルタイム処理に利用するもの。  
モノリシックなWebアプリに予測処理を組み込む。  



#### 4.2.3  バッチ処理で学習＋予測結果をAPI経由で利用する（リアルタイム処理で予測）

Webアプリとは別に，予測処理を薄くラップしたAPIサーバを用意するもの。  
バッチ処理で学習することは他のパターンと同じだが，Webアプリから予測結果を利用する場合，API経由のリアルタイム処理で予測する。  

このパータンの特徴は以下  

- Webアプリと機械学習に使うプログラミング言語が分けられる  
- Webアプリ側のイベントに対してリアルタイム処理で予測できる  
- APIサーバと通信が発生する分 レイテンシが大きくなる  



機械学習環境を自由に選べるため，プロトタイピングを高速に回せる。  
その反面，システムの規模が大きくなるため，リアルタイム処理での予測が重要でない場合には取りづらい構成。  
scikit-learnなどのライブラリを使って構築するには自前でAPIサーバを実装し，予測サーバの前にロードバランサを配置し，負荷に応じて予測サーバを増減するといった，スケールする工夫が必要。  



手軽に試したい場合は，Azure Machine Learning や Amazon Machine Learningなどの機会学習サービスや AWS Lambdaを使った予測APIをつくる などを利用する方法がある。  



#### 4.2.4  バッチ処理で学習＋予測結果をDB経由で利用する（バッチ処理で予測）

Webアプリで使い勝手の良いパターン。一番はじめに試すパターンとして無難。  
一括学習し，そのモデルを使った予測をバッチ処理で行ない，その予測結果をDBに格納する方法。  

具体的には，商品説明など変化のしにくいコンテンツを6時間毎のバッチで分類する，ある日のユーザ閲覧履歴からどのユーザクラスタに属するかを日時バッチで処理するもの。例えば，ユーザのアクセスログからメールマガジンで送付する内容をパーソナライズするなど。  



このパターンの特徴は以下  

- 予測バッチとアプリの間でDBを介してやりとりするため，Webアプリと機械学習の学習・予測を行う言語が異なっても良い。  
- 予測に必要な情報は予測バッチ実行時に存在する  
- イベントをトリガーとして即時に予測結果を返す必要がない  
- 予測にかけられる時間に余裕がある  



#### 4.2.5  リアルタイム処理で学習をする

リアルタイム処理を考えるうえで参考になるアーキテクチャは以下  

- リアルタイムレコメンドの構成としてはOrxyというフレームワーク  
- 逐次学習向けのJubatusというフレームワークも  



#### 4.2.6  各パターンのまとめ

各パターンの特徴  

| パターン                                         | 一括学習+直接予測 | 一括学習+API | 一括学習+DB | リアルタイム |
| ------------------------------------------------ | ----------------- | ------------ | ----------- | ------------ |
| 予測                                             | リクエスト時      | リクエスト時 | バッチ      | リクエスト時 |
| 予測結果の提供                                   | プロセス内API経由 | REST API経由 | 共有DB経由  | MQ経由       |
| 予測リクエストから<br />結果までのレイテンシ     | ○                 | ○            | ◎           | ◎            |
| 新規データ取得から<br />予測結果を渡すまでの時間 | 短                | 短           | 長          | 短           |
| 一件の予測処理に<br />かけられる時間             | 短                | 短           | 長          | 短           |
| Webアプリとの結合度                              | 密                | 疎           | 疎          | 疎           |
| Webアプリの<br />プログラミング言語と            | 同一              | 独立         | 独立        | 独立         |



### 4.3  ログ設計

教師データを取得するためのログ設計と特徴量について。  



#### 4.3.1  特徴量や教師データに使いうる情報

特徴量や教師データに使えそうな情報として，大きく以下3つがある。  

1. ユーザ情報  
   ユーザ登録時に設定してもらう，例えば性別のような属性情報のこと。  
2. コンテンツ情報  
   ブログサービスにおけるブログ記事や商品などのコンテンツ自身の情報。  
3. ユーザ行動ログ  
   ユーザがどのページにアクセスしたか(アクセスログ)や商品の購入などイベントを起こしたかのログ。  
   ユーザ行動ログは，広告のクリックイベントや商品購買などコンバージョンに繋がる情報を持つことが多く，教師データになりやすいので，適切に収集できるようにする必要がある。



#### 4.3.2  ログを保持する場所

ユーザ行動ログはデータ量が多くなるので，保存場所に気を付ける必要がある。  
MySQLやPostgreSQLなど業務用RDBMSに格納すると，後々全データの傾向を見たりして当たりをつけることが難しくなる。  

以下のようなデータ保持方法が適切と考えられる。  

- 分散RDBMSに格納する  
  Amazon Redshift や Google BigQueryなどのフルマネージドなクラウド型の分散DBサービスもある  
  Amazon Elastic MapReduce や Google Cloud Dataproc, Azure HDInsightなど分散処理サービスを使うことで，SQLやMapReduceだけでなくApache Sparkを使った複雑な処理も可能。  

- 分散処理基盤HadoopクラスタのHDFSに格納する  
  Apache Hive, Apache Impala, PrestoなどのSQLクエリエンジンを用いることでアクセスが容易になる  

- オブジェクトストレージに格納する  
  Amazon S3のようなオブジェクトストレージにデータを格納し，そこに対し，HiveやImpala，PrestoやAWS Athenaでクエリを直接実行する。  

- (共通) SQLでデータにアクセスできるようにする
  

  他のプログラミング言語を書かなくても様々な分析が可能になるため

これらの生データからSQLを使った集計処理等をした後，機械学習用のデータセットとして利用する。  



FluentdやApache Flume, Logstashなどのログ収集ソフトをWebアプリに入れ，保管先に転送する。  
また，Embulkのようなバッチでデータ転送したり，Apache Kafkaを活用してスケーラブルなログ収集基盤をつくったりする選択肢もある。  



#### 4.3.3  ログを設計する上での注意点

必要そうなユーザ情報やコンテンツ情報は，サービス設計時に想定しておく必要がある。  



また，現在取得しているログで教師データを作れるか，という視点も必要。  
例えば，「広告をクリックしたログ」は保存していたが「広告を表示したログ」はデータ量が多すぎるため破棄していた事例。これは「広告が表示されたが，クリックされなかった」ログが存在しないため，教師データがうまく作れず，クリック予測が行えなかった。

他にも，購買ログと商品マスターのデータから，商品の説明文と売れ行きの関係を調査したい，という事例について。商品の説明文の変更は，商品マスターを直接書き換えて運用しており，いつからいつまでどのような説明文で販売していたかという情報が欠落しており，十分な調査を行うことができなかった。  

このように，システム開発・運用する人と分析する人が分かれていると，ネガティブなデータや，変更履歴など重要なデータを捨ててしまうことがあるので注意が必要。  



ログ形式の変化にも注意が必要。システム更新でログ形式が変化し取得する情報が変わる場合がある。  
しかし，入力に使う特徴量のセットを途中で変化させることは，まず無い。  
従って，長い期間の古い情報量の少ないときの特徴量のセットを使うか，短い期間で新しい特徴量のセットを使うか，どちらが良いか検討が必要。  



### 4.4  この章のまとめ

一括学習して得られたモデルから，予測結果をどのように呼び出すかによって4つのパターンがあること。  

特徴量や教師データが有効に取得できるようログ設計し，手戻りを防止する。  



## 5章  学習のためのリソースを収集しよう

教師あり学習するために必要なリソースを収集する方法について解説。  



### 5.1  学習のためのリソースの取得方法

教師あり学習の教師データには大きく以下2つが含まれる。  

- 入力：アクセスログなどから抽出した特徴量  
- 出力：分類ラベルや予測値  



出力のラベル・値は以下の方法で付与できる。  

- サービスの中にログ取得の仕組みを用意してそこから抽出する（完全に自動）  
- コンテンツなど人が見て付与する（人力で行なう）  
- 機械的に情報を付与して 人手で確認する（自動+人力）  



以降，教師データを作るのは誰かという観点から説明。  



### 5.2  公開されたデータセットやモデルを活用する

既に世の中に存在する学習済みモデルやコンペティション用に用意されたデータセットを使い，ベースラインを学習し，それを転用する手法。こうしたリソースについての収集方法について。  



以下が有名どころ  

- [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/)  
- [Kaggle](https://www.kaggle.com/)：機械学習コンペティションサイト  
  各種コンペティションおよび一般の人が共有したデータセットがある  
- [ImageNet](http://www.image-net.org/)：タグ付きの画像を公開している  
- [Caffe | Model Zoo](http://caffe.berkeleyvision.org/model_zoo.html)：学習済みのモデルを共有  
- [Wikipediaのダンプデータ](https://ja.wikipedia.org/wiki/Wikipedia:%E3%83%87%E3%83%BC%E3%82%BF%E3%83%99%E3%83%BC%E3%82%B9%E3%83%80%E3%82%A6%E3%83%B3%E3%83%AD%E3%83%BC%E3%83%89)：日本語のテキストデータとしてよく使われる  
- [新聞コーパス](http://www.nichigai.co.jp/sales/corpus.html)：有償。こちらも日本語のテキストデータとしてよく使われる。  



これらのデータ利用時には，以下の気にするべき問題点がある。  

- モデルやデータセットは商用利用可能なライセンスか  
  商用利用可能か，必ず確認する必要がある。  
  特にラベル付きデータは大学などが科研費を使い作成していることが多く，ライセンスが研究目的に限定されていることがよくある。またライセンスは定型化されていないことが多く，問い合わせると商用利用できないケースもある。  
  また，リソースを利用し作成したモデルなどを再配布する際にも，元のリソースの制限を受ける場合があるため，参照元が明確になるように管理すべき。  
- 学習済みモデルやデータセットを自分たちが運用するシステム・サービス（ドメイン）に適用できるか  
  自分のドメインに適用するための工夫が必要になることが多くある。詳細は「半教師あり学習」や「転移学習」について調べると良いらしい。  
  特に，画像の物体認識する場合，転移学習を用い，既存の学習モデルに自分の解きたい画像の正解データセットを追加することで，少ない追加コストで目的に画像を認識するモデルを学習できる。  



### 5.3  開発者自身が教師データを作る

既存データセットだけで解ける問題は限定的なため，自分でデータセットを作る方法について。  
どのデータを特徴量にするかが性能に直結することも多いため，自分の手を動かして教師データを作るのはとても重要。  



はじめに，解きたい問題から，分類/回帰 どちらをすべきかを考える。  



例えば，ソーシャルブックマークサービス（オンラインでお気に入りのWebサイトを共有できるサービス）で，カテゴリを自動付与（予測）する問題を考える。  
まず「政治」「芸能」など，カテゴリとその定義を決める。すると，決まった数のカテゴリを予測する問題なので分類問題，ということになる。  
試しに，各カテゴリに所属するコンテンツを1000件程度ずつ収集し，人の手で分類する。「収集」の方法としては，既存コンテンツがある場合，特定のキーワードが含まれるコンテンツを正解データとする方法がある。このように何かしらの基準でコンテンツを正解のカテゴリに分類していく。  
これが最初の開発データ作り。  

機械学習で解ける問題は，人間が見て分かることがほとんど。人間がどんな情報を使ってカテゴリを分けているかということを，教師データを作成しながら注意深く洞察する。  



データのなかには，人間が見ても曖昧なデータが存在することに気付く。例えば「アイドルが大臣と選挙応援のイベントを行った」という内容のニュース記事。これは「芸能」にも「政治」にも入りそう。
このとき，この分類問題は排他的なカテゴリ分類をするのか，それとも複数のカテゴリが存在するのかを考える。それに応じて採用すべきアルゴリズムや予測方法は変わる。データを見る前に決めたカテゴリはそのままで良いのか，分類の定義を更新した方が良いのかどうかも考えて分類を進める。  

あわせて，データを人手で分類していると，例えば「記事タイトルに含まれる単語がカテゴリを分けるのに必要そう」など重要な情報が分かってくる。「必要そう」と思った情報を特徴量に含めると，性能が改善することがある。  



こうしてブラッシュアップしながら，すべてのデータに対してカテゴリを付与する頃には，他の人にも説明できるような分類の定義ができあがっているはず。
できあがった基準 や 分類に困ったコンテンツ は，判断基準と実例を残しておくと良い。ソースコードと同じで，一か月前の自分は他人だと思って，言葉で説明できる基準を整理する。  



### 5.4  同僚や友人などにデータ入力してもらう

開発者自身の1人でデータセット作りをすると，量が増えると行き詰まったり，思い込みによる偏りが発生しユーザの感覚とズレが生じたりしてしまう。  
解決法として取り組みやすいのは，同僚や友人などに協力を募る方法。  



もっともシンプルな方法は，Googleスプレッドシートなどブラウザ共有できるアプリで，判断対象のデータを列挙しラベルを付与して貰う方法がある。  

複数名に作業を依頼する場合，作業内容や判断基準についてきちんと説明しておくことが重要。  
一人で作業しているときには，自分の暗黙の基準があるはずだが，複数人で作業すると，大抵その基準がぶれてしまうため，暗黙の基準を文書化しておくことが望ましい。  

複数名で作業するときは，同一データに対して複数名に正解を付与してもらうことも重要。人によって判断がぶれてしまうこともあるため。付与された正解データが作業者間でどれくらい一致しているかを把握することで，課題の難易度を把握することができる。  
人間同士でも5割一致しないタスクは，そのデータを使って機械学習をしても解けない可能性が非常に高い。  
また，偶然一致する可能性を考慮した基準である[カッパ係数](http://www.med.osaka-u.ac.jp/pub/kid/clinicaljournalclub12.html)を使い課題の難易度を判断することもある。  
複数人で作業するときは，他の作業者の正解データを見せないようにする必要がある。見えるとバイアルとなる恐れがあるため。  



### 5.5  クラウドソーシングを活用する

データ量を集めるための別の方法としてクラウドソーシングを使う方法がある。  
クラウドソーシングとは，Amazon Mechanical TurkやYahoo!クラウドソーシング，CORWDなどを中心に行われるマイクロタスク型と呼ばれる，データ入力など短時間でできる単純な作業を多数の一般の人へ依頼する形態。  

クラウドソーシングを使ったデータ作成のメリットは主に以下。  

- 専門の作業者を雇うより作業が速く，金額も比較的安い。  
- 作業が速く終わるため，試行錯誤し易い。  
- 作業コストが低いことから，複数人に同一タスクを依頼するなど冗長性を持ったデータ作成が可能。  



一方，以下の注意が必要。  

- 作業者が短時間で解けるようにする必要があり，タスク設計が難しい。  
- 高い専門性が求められる作業は，手順の分割・詳細化などが必要。  
- 作業結果の質を担保するために，結果を利用する際の工夫が必要。  



データを得た後に質をどう評価するかについても予め考えておく必要がある。例えば，分類用データの場合「カテゴリごとにサンプリングして適切なカテゴリが付与されているかチェックする」というように少量のサンプルに対してチェックする方法がよくとられる。  



### 5.6  サービスに組み込み，ユーザに入力してもらう

教師データ収集を自分たちで行なわず，サービスのユーザに付与してもらうこともある。  

自社サービスを展開している場合に，サービスを良く知っているユーザに協力して貰えるのは大きな魅力。  



例えば，直接的に簡単なアンケートをとる，コンテンツのタグをユーザに付与して貰う，コンテンツのカテゴリを申請してもらう，検索結果や推薦結果の中の不適切なコンテンツを報告して貰うなど，データ収集の仕組みをサービスの中に埋め込んでしまう方法もある。  
例えば，人間かどうかを判別するために画像中の文字を読ませるreCAPTHAがある。  



このような仕組みが作れると，新規コンテンツに対しても継続的に正解データを増やし続けることができるので，変化に追従しやすくなるメリットもある。  



### 5.7  この章のまとめ
教師あり学習のためのリソース収集方法について扱った。  

十分な量の良質データ収集が，機械学習にとって重要ポイントなので適切な方法を採用する。  



## 6章  効果検証

効果検証の基礎となる統計的検定と因果効果推論，検証の手法であるA/Bテストについて。  



### 6.1  効果検証の概要

効果検証とはある施策によってもたらされた効果を推定すること。「Yという事象がXによってどれだけ影響を受けたか」を明らかにすること。  



例えば，広告配信サービスであれば「広告表示1000下位あたりの収益額が新機能によってどれだけ増えたか」を検証する。  
検証結果から，リリースした機能を 維持する/取り下げるの 判断をデータを根拠にして行える。  



#### 6.1.1  効果検証までの道程

効果検証に至るまでの流れは以下の通り。  
`問題定義 -> 仮説設定 -> アクション（開発） -> 効果検証`  
検証の指標を仮説設定の段階で決めておく必要がある。  
指標は計測が可能である必要があり，もし計測する仕組みがない場合は，先にそちらを開発すべき。  



例えば，ソーシャルネットワークサービスの場合は以下。  

| フェーズ   | 内容                                                         |
| ---------- | ------------------------------------------------------------ |
| 問題定義   | ユーザのアクティブ率を上げたい                               |
| 仮説設定   | ユーザにマッチするコンテンツを推薦して表示することで，平均滞在時間が伸びる。 |
| アクション | コンテンツのリコメンドシステムの開発                         |
| 効果検証   | 平均滞在時間が伸びたか                                       |



例えば，インターネット広告配信の場合は以下。  

| フェーズ   | 内容                                                         |
| ---------- | ------------------------------------------------------------ |
| 問題定義   | 利益率を上げたい                                             |
| 仮説設定   | 広告がクリックされるかどうかの予測精度を上げることで，<br />広告オークションの買い付けコストを下げられる。 |
| アクション | 広告のクリック率予測器と予測値を利用した入札ロジックの開発   |
| 効果検証   | コンバージョン1件あたりのコストが下がったか                  |



#### 6.1.2  オフラインで検証しにくいポイント

機械学習モデルの性能評価は3章にある通り，オフラインでも実施可能。  
オフラインで検証が難しい効果には何があるか。  



##### 経済効果

事業の粗利や売上といった数値に責任を持つ人の興味は「利益をどれだけ押し上げたか」という点。  
機械学習モデルの予測精度が～%向上したなどではない。  
例えば，Netflixのレコメンドシステムのビジネス価値としては解約率の低下があり，10億ドル/年の効果があったとしている。  これはオフライン検証でレコメンド精度から導出は難しい値。



##### ログを経由した副作用

"機械学習モデルを反映したシステム"から得られるログを使用して学習すると，ログは機械学習モデルのバイアスがかかっているので，それが技術的負債になる的な話だと思うけどよく理解できていない。  
あと，同じログを学習データとしている他の予測器にも影響を与えることも触れてくれている。  

以下ペーパーが元だけど読めていない。  
[Hidden Technical Debt in Machine Learning Systems](https://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf)  



### 6.2  仮説検定の枠組み

仮説検定とは効果検証のベースとなるもので，母集団に有意な差があることをサンプルを使って確認する手法。  
統計の基礎として以下は知っておく必要がある。  

- [大数の法則](https://atarimae.biz/archives/16598)：サンプルサイズが大きければ大きいほど，サンプル平均は極端な値を採る確率が低くなっていき，母平均に近い値を採る確率が高くなっていくこと。  
- [中心極限定理](https://atarimae.biz/archives/17470)：n個のサンプル平均の確率分布はnが十分に大きければ平均μ，分散$\frac{\sigma^{2}}{n}$の正規分布に近似できる。  



#### 6.2.1  コインは歪んでいるか

コイントスゲームの例で考える。  
直近20回で 表が15回・裏が5回 出ているとする。  
直感的には表が出過ぎているように思うが，どう判断したら良いか。

`TestScikitLearn\src\0621_plot_coin_toss.py#plot_coin_toss()`から表が15回以上出るのは2%に過ぎないことが分かる。  
このことから，表が出過ぎていると結論づけるのが検定の考え方。  



今回の例において，それぞれ以下と呼ぶ。  

- 帰無仮説：表が出る確率は50%であると した仮説のこと  
- 対立仮説：表が出る確率は50％と異なるとする仮説のこと  
- p値：帰無仮説が真であるとしたときの確率のこと  
- 有意水準：p値の閾値，例えば"5%より低いことが起きていたら帰無仮説を棄却する"と判断する値  
  今回は0.02のため，0.05としたら，帰無仮説は棄却される。0.01としたら棄却されない。  
- 標本（サンプル）：直近のトス  
- 標本サイズ：20  
- 母集団：過去から未来までの全てのトス  



#### 6.2.2  二群の母比率の差の検定

ECサイトを運営していて，集客のために2つの広告配信サービス(A, B)に出稿する例で考える。  
それぞれの広告配信サービス経由で流入したユーザの行動比較をする。  

流入経路別ユーザの継続化データが以下の通りだったとする。  

| 流入元 | 流入人数 | 継続利用人数 | 継続化率 |
| ------ | -------- | ------------ | -------- |
| A      | 205      | 40           | 19.5%    |
| B      | 290      | 62           | 21.4     |

Bの方が良さそうに見えるが，誤差なのか判断できない。仮説件天地の枠組みを適用して考える。  
帰無仮説は「母集団AとBで継続化率は等しい」，対立仮説は「母集団AとBで継続化率に差がある」，有意水準は0.05とする。  
`TestScikitLearn/src/compare_ad.py#compare_advertisement()`で求められる通り，p値は0.69となり，帰無仮説が棄却できないことが分かる。このときは，帰無仮説が正しいとも間違っているとも言えない。  



#### 6.2.3  偽陽性と偽陰性

2つの例で，p値が事前に定めた有意水準を下回った場合に帰無仮説を棄却するのが仮説検定の枠組みだと説明した。稀にしか起こらないことが起こったから帰無仮説を棄却する判断をする以上，帰無仮説が真であったとしても有意水準の確率で誤って帰無仮説を棄却してしまう。  
例えば，有意水準5%で検定する場合，2郡の間に差が無かったとしても5%の確率で，差があると判断することになる。この誤った発見を偽陽性と呼ぶ。病気の検査で陽性が出たものの，後の精密検査で異常なしと判断されることがある。これが偽陽性。検出すべき疾患を見逃した場合は偽陰性。  

仮説検定では検定力を検定結果の評価に利用する。  
`検定力 = 1 - 有意差があるのに有意差がないと判断する確率`  



### 6.3  仮説検定の注意点

p値を利用した研究の再現性の低さから，p値の閾値を0.05から0.005にすべきとの声明が発表されるなど，仮説検定は批判の対象となっている。仮説検定の誤った使用は，偽陽性の確率を上げ，p値のみによる意思決定は本質を見逃す。  

ここでは，検定の誤った使用パターンとしてありがちなものを紹介。  



#### 6.3.1  繰り返し検定をしてしまう

仮説検定で注意が必要な点は，検定対象の標本を固定すること。  
有意差が出ないからといって標本を変えて再試験してしまうと有意水準の意味がなくなる。  

`TestScikitLearn\src\0621_plot_coin_toss.py#iterate_testing()`から確認できるように，標本を変えて再試験しているとp値が0.05を下回ることがある。このように検定を繰り返すと，いつか有意差が出てしまう。



#### 6.3.2  有意差とビジネスインパクト

平均に差があることの検定において，標本サイズがどう結果(p値)に影響を与えるか。  

`TestScikitLearn\src\0621_plot_coin_toss.py#sample_size_difference()`から確認できるように，ここでは標本サイズが170万を越えたあたりでp値がゼロに近付き，有意差を示す。  
これは推定量のばらつきを表す標準誤差が，標本サイズの増大に従って小さくなるため。標本サイズを増やして行けば，わずかな差でも有意差となる。  
重要なのは有意差があるということとビジネス上のインパクトは別である点。  

#### 6.3.3  複数の検定を同時に行う

繰り返し検定してしまうパターンに近いのが複数の仮説を検定するケースで，多重検定と呼ぶ。  
例えば，M個の説明変数の候補$X \in X_{0}, X_{1}, ..., X_{M}$から目的変数に有意に相関のあるものを抽出したいとなると，M回の独立な検定が必要になる。$X_{i}$が目的変数と独立であるという帰無仮説を棄却できれば有意に相関があるとできるM個の仮説を有意水準αで検定すると，誤って一つでも帰無仮説を棄却する確率は$1-(1-α)^{M}$。  
`α=0.05`のときにMを増やしていくときのプロットを見ると，M=80でほぼ100%になる。ここから多重検定は偽陽性を著しく上昇させるのが分かる。このことから，多重検定において偽陽性を抑制する様々な方法がある。  



多重検定において偽陽性を抑制するアプローチには以下がある。  

- 1つでも誤った発見をする確率を抑制するもの  
  シンプルな方法はBonferroni法。有意水準を`αからα/M`に変更する。
  ただし，このアプローチは検定力が著しく落ちる。検定力が欲しいケースでは後者のアプローチをとる。  
- 誤った発見の割合を抑制するもの  



### 6.4  因果効果の推定

仮説検定は標本から母集団の性質を推定する方法。次は母集団に対する効果を推定する。  
「Yという事象が施策Xによってどれだけ影響を受けたか」を明かにするために，因果推論における因果効果の考え方について。  



#### 6.4.1  ルービンの因果モデル

インターネット広告について考える。因果推論では以下の通り呼ぶ。  

- 介入：広告を見せること  
- 結果変数：購買行動  
- 介入群 / 実験群：介入した標本  
- 対象群 / 統制群：介入していない標本  

広告の効果は，広告を見たときと見なかったときの購買行動の差とすることができる。  
しかし，個人の単位では観測可能な結果変数は介入を行なった場合か否かのどちらかに限定される。  
広告に接触したAさんが広告に接触しなかったケース反事実となり観測できない。  

ルービンの因果モデルでは，観測できないが潜在的に存在し得る結果変数を考えて，これを潜在的結果変数と呼ぶ。
購買に至ったかどうかの結果変数を$Y \in 0, 1$，介入時と介入していないときの結果をそれぞれ$Y_{1}, Y_{0}$として観測結果を表にすると以下の通り。  

| ユーザ | 介入有無 | $Y_{0}$ | $Y_{1}$ |
| ------ | -------- | ------- | ------- |
| 1      | 1        | -       | 1       |
| 2      | 1        | -       | 0       |
| ...    | ...      | ...     | ...     |
| 6      | 0        | 1       | -       |
| ...    | ...      | ...     | ...     |
| n      | 0        | 0       | -       |

個人対では$Y_{1}-Y_{0}$を測ることはできない。  

しかし知りたいのは標本への効果ではなく，母集団への効果。  
母集団への効果は個人単位の購買結果の差の期待値$E(Y_{1}-Y_{0})$と考えられる。これを平均処置効果(ATE)と呼ぶ。  
$ 平均処置効果 = E(Y_{1}-Y_{0})=E(Y_{1})-E(Y_{0}) $ 
以降は平均処理効果をいかに求めるかについて。   

#### 6.4.2  セレクションバイアス

求めたい平均処置効果の計算について，なんとなく「介入群の結果変数の平均」と「統制群の結果変数の平均」の差をとれば良いような気がする。しかし，この差は$E(Y_{1}|介入あり) - E(Y_{0}|介入なし)$であり，介入有無と結果変数に相関ある平均処置効果の式と一致しない。  
インターネット広告の例に戻ると，購買行動に繋がりそうなユーザを狙って介入をするのが一般的。  
このため通常の観測結果では，介入群は元々，購買意欲が高い集団となり，介入群と統制群に差があることになる。この現象はセレクションバイアスと呼び，インターネット広告配信に限らず様々なデータに現れる。  



#### 6.4.3  ランダム化比較試験

$ 平均処置効果 = E(Y_{1}-Y_{0})=E(Y_{1})-E(Y_{0}) $と$E(Y_{1}|介入あり) - E(Y_{0}|介入なし)$が一致するケースもある。  
それは介入群と統制群に差がないとき。この状態を作り出し比較する手法がランダム化比較試験。  
標本に対してランダムに介入有無を決定することで，性質の等しい2郡の片方に介入した状態をつくる。  
例えば，介入群にのみ広告を表示後，介入群と統制群にアンケートを実施する。  



#### 6.4.4  過去との比較は難しい

売上/粗利などは強い季節性を持っており，過去との比較による因果効果の推定は非常に困難。  
ランダム化比較試験で同じタイムスパンにおける2郡を比較する方が簡潔で，施策による介入効果以外の要因を揃えることが可能。  



### 6.5  A/Bテスト

A/Bテストを本番環境を行なうことで，「セレクションバイアスの除去」と「2郡の同時比較による時間変化影響の除去」のもとで，施策効果検証を行うことができる。  

A/Bテストの流れは以下の通り。  
`2郡の抽出 -> A/Aテスト -> 片方に介入 -> 結果の確認 -> テスト終了`  

以降，ポイントについて解説。  



#### 6.5.1  2群の抽出と標本サイズ

仮説検定の節で標本サイズとp値の関係について扱った。小さな差を検出したければ多くの標本が必要になる。  
A/Bテストでは事前に標本サイズを決定しなければならないパターンがある。例を以下に2つ示す。  

| ケース | 検証方法                                                     | 標本サイズ                           |
| ------ | ------------------------------------------------------------ | ------------------------------------ |
| A      | ユーザを2群に割り振り，介入後に1人あたりの売上の平均に<br />違いが出るか検証する。 | 2郡を作った時点で固定                |
| B      | ユーザ新規登録画面の新デザインが既存の物と比較して<br />登録完了率に違いがあるか検証する。新規ユーザが訪れたとき<br />一定の確率で新デザインを表示する。 | 新規ユーザの訪問がある限り増え続ける |

ケースAでは標本サイズが足りない場合，テストのやり直しになるため標本サイズの見積もりは必須。一方で標本サイズが大きいとテストの影響を受けるユーザ数が増え，施策がマイナスの効果を及ぼすことも考えられるため，多すぎるのも問題。別の問題として全ユーザを半々にしてテストすると，他のテストを同時実施できなくなる。また，介入群・統制群の使いまわしをすると前のテストの影響を引き継いでしまうため，テスト実施ごとに抽出を行なうべき。  



#### 6.5.2  A/Aテストによる均質さの確認

ランダム抽出により等質な2郡が得られるはずだが，それを確認するのがA/Aテスト。  
2群を抽出後に時間をおいて，2郡に差がなければ片方に介入する。  
もしくは過去データから差がないことを確認できれば即座にテストを開始できる。  



#### 6.5.3  A/Bテストの仕組み作り

A/Bテストを実施するには，サービスがA/Bテストに対応している必要がある。  
ランダム抽出や介入有無の設定に加え，学習データの分離が必要になる。  
複数の予測器をA/Bテストで比較しているとき，学習データ経由で互いに影響を受けると本来の動作にならないため，その場合は学習データの分離が必要。  

MicrosoftのA/Bテストチームは以下の機能を活用。  

- 効果の悪いテストを早期に止めるためのアラート・自動停止  
- テスト同士で相互作用があるものを自動で検出  



#### 6.5.4  テストの終了

テスト結果の判断を早く行うことには以下から価値がある。  

- 良い施策をより早く全体に適用できる  
- 効果の悪い施策は速くやめるべき  

A/Bテストで起きるのが，終了時期を決められずテストを放置してしまうこと。  
テスト実施機関にリミットを設定すると良い。  
新たな観測データが逐次得られるテストの終了タイミングは自明ではないが，母平均が異なるテストであれば平均値の時系列プロットに信頼区間を重ねることで判断できる。  
信頼区間が分離したら差があるとし，なかなか信頼区間が分離しない場合，いずれ有意差が出たとしても差は小さく効果は見込めないと判断して中止できる。  



### 6.6  この章のまとめ

工事の抜き取り検査と違い，Webサービスの場合は低コストで多くの標本が利用できる。そのため限られた標本を使って母集団の性質を予測する統計のメリットは感じられないようにも感じられるが，副作用をともなうA/Bテストにおいてはその影響を最小化できる。  



## 第II部
## 7章  映画の推薦システムをつくる
### 7.1  シナリオ
#### 7.1.1  推薦システムとは
#### 7.1.2  応用シーン
### 7.2  推薦システムをもっと知ろう
#### 7.2.1  データの設計と取得
#### 7.2.2  明示的データと暗黙的データ
#### 7.2.3  推薦システムのアルゴリズム
#### 7.2.4  ユーザー間型協調フィルタリング
#### 7.2.5  アイテム間型協調フィルタリング
#### 7.2.6  モデルベース協調フィルタリング
#### 7.2.7  内容ベースフィルタリング
#### 7.2.8  協調フィルタリングと内容ベースフィルタリングの得手・不得手
#### 7.2.9  評価尺度
### 7.3  MovieLensのデータの傾向を見る
### 7.4  推薦システムの実装
#### 7.4.1  Factorization Machineを使った推薦
#### 7.4.2  いよいよFactorizatoin Machineで学習する
#### 7.4.3  ユーザーと映画以外のコンテキストも加える
### 7.5  この章のまとめ
## 8章  Kickstarterの分析，機械学習を使わないという選択肢
### 8.1  KickstarterのAPIを調査する
### 8.2  Kickstarterのクローラを作成する
### 8.3  JSONデータをCSVに変換する
### 8.4  Excelで軽く眺めてみる
### 8.5  ピボットテーブルでいろいろと眺めてみる
### 8.6  達成したのにキャンセルされたプロジェクトを見てみる
### 8.7  国別に見てみる
### 8.8  レポートを作る
### 8.9  今後行いたいこと
### 8.10  おわりに
## 9章  Uplift Modelingによるマーケティング資源の効率化
### 9.1  Uplift Modelingの四象限のセグメント
### 9.2  A/Bテストの拡張を通じたUplift Modelingの概要
### 9.3  Uplift Modelingのためのデータセット生成
### 9.4  2つの予測モデルを利用したUplift Modeling
### 9.5  Uplift Modellingの評価方法，AUUC
### 9.6  実践的な問題での活用
### 9.7  Uplift Modelingを本番投入するには
### 9.8  この章のまとめ
