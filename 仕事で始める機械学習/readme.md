# 仕事ではじめる機械学習
仕事ではじめる機械学習のノート  
https://www.oreilly.co.jp/books/9784873118215/  

---
# 目次
<!-- TOC depthFrom:1 depthTo:6 withLinks:1 updateOnSave:1 orderedList:0 -->
<!-- https://github.com/Sorix/markdown-toc/ -->
- [仕事ではじめる機械学習](#仕事ではじめる機械学習)
	- [1章  機械学習プロジェクトのはじめ方](#1章--機械学習プロジェクトのはじめ方)
		- [1.1  機械学習はどのように使われるのか](#11--機械学習はどのように使われるのか)
		- [1.2  機械学習プロジェクトの流れ](#12--機械学習プロジェクトの流れ)
			- [1.2.1  問題を定式化する](#121--問題を定式化する)
			- [1.2.2  機械学習をしなくて良い方法を考える](#122--機械学習をしなくて良い方法を考える)
			- [1.2.3  システム設計を考える](#123--システム設計を考える)
			- [1.2.4  アルゴリズムを選定する](#124--アルゴリズムを選定する)
			- [1.2.5  特徴量，教師データとログの設計をする](#125--特徴量教師データとログの設計をする)
			- [1.2.6  前処理をする](#126--前処理をする)
			- [1.2.7  学習・パラメータチューニング](#127--学習パラメータチューニング)
			- [1.2.8  システムに組み込む](#128--システムに組み込む)
		- [1.3  実システムにおける機械学習の問題点への対処方法](#13--実システムにおける機械学習の問題点への対処方法)
			- [1.3.1  人手でゴールドスタンダードを用意して，予測性能のモニタリングをする](#131--人手でゴールドスタンダードを用意して予測性能のモニタリングをする)
			- [1.3.2  予測モデルをモジュール化をしてアルゴリズムのA/Bテストができるようにする](#132--予測モデルをモジュール化をしてアルゴリズムのabテストができるようにする)
			- [1.3.3  モデルのバージョン管理をして，いつでも切り戻し可能にする](#133--モデルのバージョン管理をしていつでも切り戻し可能にする)
			- [1.3.4  データ処理のパイプラインごと保存する](#134--データ処理のパイプラインごと保存する)
			- [1.3.5  開発/本番環境の言語/フレームワークは揃える](#135--開発本番環境の言語フレームワークは揃える)
		- [1.4  機械学習を含めたシステムを成功させるには](#14--機械学習を含めたシステムを成功させるには)
		- [1.5  この章のまとめ](#15--この章のまとめ)
	- [2章  機械学習で何ができる？](#2章--機械学習で何ができる)
		- [2.1  どのアルゴリズムを選ぶべきか？](#21--どのアルゴリズムを選ぶべきか)
		- [2.2  分類](#22--分類)
			- [2.2.1  パーセプトロン](#221--パーセプトロン)
			- [2.2.2  ロジスティック回帰](#222--ロジスティック回帰)
			- [2.2.3  SVM](#223--svm)
			- [2.2.4  ニューラルネットワーク](#224--ニューラルネットワーク)
			- [2.2.5  k-NN](#225--k-nn)
			- [2.2.6  決定木，ランダムフォレスト，GBDT](#226--決定木ランダムフォレストgbdt)
		- [2.3  回帰](#23--回帰)
			- [2.3.1  線形回帰の仕組み](#231--線形回帰の仕組み)
		- [2.4  クラスタリング・次元削減](#24--クラスタリング次元削減)
			- [2.4.1  クラスタリング](#241--クラスタリング)
			- [2.4.2  次元削減](#242--次元削減)
		- [2.5  その他](#25--その他)
			- [2.5.1  推薦](#251--推薦)
			- [2.5.2  異常検知](#252--異常検知)
			- [2.5.3  頻出パターンマイニング](#253--頻出パターンマイニング)
			- [2.5.4  強化学習](#254--強化学習)
		- [2.6  この章のまとめ](#26--この章のまとめ)
	- [3章  学習結果を評価しよう](#3章--学習結果を評価しよう)
		- [3.1  分類の評価](#31--分類の評価)
			- [3.1.1  正解率を使えば良いのか？](#311--正解率を使えば良いのか)
			- [3.1.2  データ数の偏りを考慮する適合率と再現率](#312--データ数の偏りを考慮する適合率と再現率)
			- [3.1.3  F値でバランスの良い性能を見る](#313--f値でバランスの良い性能を見る)
			- [3.1.4  混同行列を知る](#314--混同行列を知る)
			- [3.1.5  多クラス分類の平均のとり方: マイクロ平均，マクロ平均](#315--多クラス分類の平均のとり方-マイクロ平均マクロ平均)
			- [3.1.6  分類モデルを比較する](#316--分類モデルを比較する)
		- [3.2  回帰の評価](#32--回帰の評価)
			- [3.2.1  平均二乗誤差](#321--平均二乗誤差)
			- [3.2.2  決定係数](#322--決定係数)
		- [3.3  機械学習を組み込んだシステムのA/Bテスト](#33--機械学習を組み込んだシステムのabテスト)
		- [3.4  この章のまとめ](#34--この章のまとめ)
	- [4章  システムに機械学習を組み込む](#4章--システムに機械学習を組み込む)
		- [4.1  システムに機械学習を含める流れ](#41--システムに機械学習を含める流れ)
		- [4.2  システム設計](#42--システム設計)
			- [4.2.1  混乱しやすい「バッチ処理」と「バッチ学習」](#421--混乱しやすいバッチ処理とバッチ学習)
			- [4.2.2  バッチ処理で学習＋予測結果をWebアプリケーションで直接算出する（リアルタイム処理で予測）](#422--バッチ処理で学習予測結果をwebアプリケーションで直接算出するリアルタイム処理で予測)
			- [4.2.3  バッチ処理で学習＋予測結果をAPI経由で利用する（リアルタイム処理で予測）](#423--バッチ処理で学習予測結果をapi経由で利用するリアルタイム処理で予測)
			- [4.2.4  バッチ処理で学習＋予測結果をDB経由で利用する（バッチ処理で予測）](#424--バッチ処理で学習予測結果をdb経由で利用するバッチ処理で予測)
			- [4.2.5  リアルタイム処理で学習をする](#425--リアルタイム処理で学習をする)
			- [4.2.6  各パターンのまとめ](#426--各パターンのまとめ)
		- [4.3  ログ設計](#43--ログ設計)
			- [4.3.1  特徴量や教師データに使いうる情報](#431--特徴量や教師データに使いうる情報)
			- [4.3.2  ログを保持する場所](#432--ログを保持する場所)
			- [4.3.3  ログを設計する上での注意点](#433--ログを設計する上での注意点)
		- [4.4  この章のまとめ](#44--この章のまとめ)
	- [5章  学習のためのリソースを収集しよう](#5章--学習のためのリソースを収集しよう)
		- [5.1  学習のためのリソースの取得方法](#51--学習のためのリソースの取得方法)
		- [5.2  公開されたデータセットやモデルを活用する](#52--公開されたデータセットやモデルを活用する)
		- [5.3  開発者自身が教師データを作る](#53--開発者自身が教師データを作る)
		- [5.4  同僚や友人などにデータ入力してもらう](#54--同僚や友人などにデータ入力してもらう)
		- [5.5  クラウドソーシングを活用する](#55--クラウドソーシングを活用する)
		- [5.6  サービスに組み込み，ユーザに入力してもらう](#56--サービスに組み込みユーザに入力してもらう)
		- [5.7  この章のまとめ](#57--この章のまとめ)
	- [6章  効果検証](#6章--効果検証)
		- [6.1  効果検証の概要](#61--効果検証の概要)
			- [6.1.1  効果検証までの道程](#611--効果検証までの道程)
			- [6.1.2  オフラインで検証しにくいポイント](#612--オフラインで検証しにくいポイント)
		- [6.2  仮説検定の枠組み](#62--仮説検定の枠組み)
			- [6.2.1  コインは歪んでいるか](#621--コインは歪んでいるか)
			- [6.2.2  二群の母比率の差の検定](#622--二群の母比率の差の検定)
			- [6.2.3  偽陽性と偽陰性](#623--偽陽性と偽陰性)
		- [6.3  仮説検定の注意点](#63--仮説検定の注意点)
			- [6.3.1  繰り返し検定をしてしまう](#631--繰り返し検定をしてしまう)
			- [6.3.2  有意差とビジネスインパクト](#632--有意差とビジネスインパクト)
			- [6.3.3  複数の検定を同時に行う](#633--複数の検定を同時に行う)
		- [6.4  因果効果の推定](#64--因果効果の推定)
			- [6.4.1  ルービンの因果モデル](#641--ルービンの因果モデル)
			- [6.4.2  セレクションバイアス](#642--セレクションバイアス)
			- [6.4.3  ランダム化比較試験](#643--ランダム化比較試験)
			- [6.4.4  過去との比較は難しい](#644--過去との比較は難しい)
		- [6.5  A/Bテスト](#65--abテスト)
			- [6.5.1  2群の抽出と標本サイズ](#651--2群の抽出と標本サイズ)
			- [6.5.2  A/Aテストによる均質さの確認](#652--aaテストによる均質さの確認)
			- [6.5.3  A/Bテストの仕組み作り](#653--abテストの仕組み作り)
			- [6.5.4  テストの終了](#654--テストの終了)
		- [6.6  この章のまとめ](#66--この章のまとめ)
	- [第II部](#第ii部)
	- [7章  映画の推薦システムをつくる](#7章--映画の推薦システムをつくる)
		- [7.1  シナリオ](#71--シナリオ)
			- [7.1.1  推薦システムとは](#711--推薦システムとは)
			- [7.1.2  応用シーン](#712--応用シーン)
		- [7.2  推薦システムをもっと知ろう](#72--推薦システムをもっと知ろう)
			- [7.2.1  データの設計と取得](#721--データの設計と取得)
			- [7.2.2  明示的データと暗黙的データ](#722--明示的データと暗黙的データ)
			- [7.2.3  推薦システムのアルゴリズム](#723--推薦システムのアルゴリズム)
			- [7.2.4  ユーザー間型協調フィルタリング](#724--ユーザー間型協調フィルタリング)
			- [7.2.5  アイテム間型協調フィルタリング](#725--アイテム間型協調フィルタリング)
			- [7.2.6  モデルベース協調フィルタリング](#726--モデルベース協調フィルタリング)
			- [7.2.7  内容ベースフィルタリング](#727--内容ベースフィルタリング)
			- [7.2.8  協調フィルタリングと内容ベースフィルタリングの得手・不得手](#728--協調フィルタリングと内容ベースフィルタリングの得手不得手)
			- [7.2.9  評価尺度](#729--評価尺度)
		- [7.3  MovieLensのデータの傾向を見る](#73--movielensのデータの傾向を見る)
		- [7.4  推薦システムの実装](#74--推薦システムの実装)
			- [7.4.1  Factorization Machineを使った推薦](#741--factorization-machineを使った推薦)
			- [7.4.2  いよいよFactorizatoin Machineで学習する](#742--いよいよfactorizatoin-machineで学習する)
			- [7.4.3  ユーザーと映画以外のコンテキストも加える](#743--ユーザーと映画以外のコンテキストも加える)
		- [7.5  この章のまとめ](#75--この章のまとめ)
	- [8章  Kickstarterの分析，機械学習を使わないという選択肢](#8章--kickstarterの分析機械学習を使わないという選択肢)
		- [8.1  KickstarterのAPIを調査する](#81--kickstarterのapiを調査する)
		- [8.2  Kickstarterのクローラを作成する](#82--kickstarterのクローラを作成する)
		- [8.3  JSONデータをCSVに変換する](#83--jsonデータをcsvに変換する)
		- [8.4  Excelで軽く眺めてみる](#84--excelで軽く眺めてみる)
		- [8.5  ピボットテーブルでいろいろと眺めてみる](#85--ピボットテーブルでいろいろと眺めてみる)
		- [8.6  達成したのにキャンセルされたプロジェクトを見てみる](#86--達成したのにキャンセルされたプロジェクトを見てみる)
		- [8.7  国別に見てみる](#87--国別に見てみる)
		- [8.8  レポートを作る](#88--レポートを作る)
		- [8.9  今後行いたいこと](#89--今後行いたいこと)
		- [8.10  おわりに](#810--おわりに)
	- [9章  Uplift Modelingによるマーケティング資源の効率化](#9章--uplift-modelingによるマーケティング資源の効率化)
		- [9.1  Uplift Modelingの四象限のセグメント](#91--uplift-modelingの四象限のセグメント)
		- [9.2  A/Bテストの拡張を通じたUplift Modelingの概要](#92--abテストの拡張を通じたuplift-modelingの概要)
		- [9.3  Uplift Modelingのためのデータセット生成](#93--uplift-modelingのためのデータセット生成)
		- [9.4  2つの予測モデルを利用したUplift Modeling](#94--2つの予測モデルを利用したuplift-modeling)
		- [9.5  Uplift Modellingの評価方法，AUUC](#95--uplift-modellingの評価方法auuc)
		- [9.6  実践的な問題での活用](#96--実践的な問題での活用)
		- [9.7  Uplift Modelingを本番投入するには](#97--uplift-modelingを本番投入するには)
		- [9.8  この章のまとめ](#98--この章のまとめ)

<!-- /TOC -->

---
## 1章  機械学習プロジェクトのはじめ方
機械学習の概要，プロジェクトの流れ，機械学習特有の問題，チームづくりについて紹介  
Pythonの機械学習ライブラリscikit-learnを使うことを前提に説明  

---
### 1.1  機械学習はどのように使われるのか
skip  

---
### 1.2  機械学習プロジェクトの流れ
以下の流れで進めると良い  
1. 解きたい課題を機械学習で解ける問題設定に落としこむ  
	　問題を定式化する -> 機械学習をしないで良い方法を考える  
1. 解くための 道具選び と 前処理  
	　システム設計を考える -> アルゴリズムを選定する  
	　-> 特徴量，教師データとログの設計をする -> 前処理をする  
1. モデルの作成  
	　学習・パラメータチューニング  
1. サービスへの組み込み  
	　システムに組み込む

機械学習で 何ができて何ができなさそうか 判断できるようになるためには  
「機械学習でこういう課題を解決した」という事例を見たとき 以下を意識して調べると良い  
- どういったアルゴリズムで解決したか  
- どのようなデータをFeatureにしているか  
- 機会学習をどのように組み込んでいるか  

#### 1.2.1  問題を定式化する
目的を明確にし 仮説を立て アクション可能なレベルにする  

例えば 目的「生産コストを減らす」から (仮説「不良が減ればコストが減る」)  
アクション可能なレベル「どこで不良が起こっているか特定するために機械学習を使う」  

この過程で ビジネス上の指標 KPI(Key Performance Indicator)を仮で良いので決める  

#### 1.2.2  機械学習をしなくて良い方法を考える
ビジネスで機械学習を利用する際に満たすべき条件  
- 大量データに対し 高速に安定して判断を求める必要がある  
- 予測結果に 一定の間違いが含まれることが許容できる  

この条件を満たしたうえで まずはMVP(\*)を作り 立てた仮説の筋が良いか悪いかを確認すべき  
　\* MVP: Minimu Viable Product 最低限の顧客価値を生み出す最小プロダクト

MVPを作る際に有用なOSS: Apache Solr や Elasticsearch の More Like This 機能

#### 1.2.3  システム設計を考える
設計で重要なポイントは以下  
- 予測結果をどういう形で利用するのか -> 詳細は [4章 システムに機械学習を組み込む](#4章--システムに機械学習を組み込む) 参照  
- 予測誤りをどこで吸収するのか  

この段階で 撤退ライン(例: 2ヵ月で90%の予測性能を達成する) を決めておくと良い  
予測性能の決め方は 3章 学習結果を評価しよう を参照  

#### 1.2.4  アルゴリズムを選定する
アルゴリズム選定の指針の詳細は [2章 機械学習で何ができる？](#2章--機械学習で何ができる) を参照  

#### 1.2.5  特徴量，教師データとログの設計をする
特徴量(Feature)の設計 の考え方  
- ビジネスドメインの知識を持った人と協力して 何がその現象に影響を与えそうか確認する  
	例: タービンの不具合検出に 過去の経験を元にハンマーで叩いた音をFeatureとした
- 後から不要なデータを削ることはできるけど 必要なデータを遡って取得することはできない  
- 晴れ, 曇りのようなFeatureはカテゴリカル変数と言い  
	ダミー変数(数値データ)に変換して処理する  
	scikit-learnでダミー変数への変換はLabelEncoder, OneHotEncoder クラスが利用可能  

教師データを用意するために  
- 質の良い正解ラベルをどのように取得するかが重要  
	正解ラベル収集の詳細は [5章 学習のためのリソースを収集しよう](#5章--学習のためのリソースを収集しよう) を参照  
- 元となる情報をWebアプリのログから取得することが よく行われる  
	Featureを抽出するためのログ設計の詳細については [4.3  ログ設計](#43--ログ設計) 参照  

#### 1.2.6  前処理をする
- テキスト形式のデータ  
	単語に分割して頻度を変えたり 低頻度を除去したり ダミー変数に変換したり
- 数値データ  
	欠損値のデータ処理をしたり 異常値を除外したり 正規化したり  

ここに多くの時間を取られる

#### 1.2.7  学習・パラメータチューニング
機械学習のパラメタを試行錯誤しながら変えて より良い結果がでるパラメタを探索する  

いきなり予測性能99.9%のような高い性能が出た場合  
過学習(Overfitting) や DataLeakage が発生していないか疑うべき  

性能改善には 誤判定した予測結果から エラー分析(何が誤りの原因か, 共通項はないか)する  

#### 1.2.8  システムに組み込む
機械学習のロジックをシステムに組み込んだら  
予測性能 と それに伴うビジネスインパクト(KPI) をモニタリングする  

入力の傾向が変わり(トレンドが変わり) 同じ予測モデルを使い続けていると  
予測性能が劣化する場合がある そのときは [手順5](#125--特徴量教師データとログの設計をする)～[7](#127--学習パラメータチューニング) に立ち戻って改善する  

改善し続けるため KPIをトラックし易いよう  
ダッシュボードを作ったり 異常時にアラートを飛ばす仕組みを作る  

---
### 1.3  実システムにおける機械学習の問題点への対処方法
機械学習システムを継続して 改善/メンテナンス するために重要なポイント について
// この章 全体的にちゃんと理解できてない感ある  

#### 1.3.1  人手でゴールドスタンダードを用意して，予測性能のモニタリングをする
定期的に 人工データセット(x, y)作成 -> 予測性能の測定 を実施してモニタリングする  

これにより 予測モデルの定期的評価(テストでき) や トレンド変化による劣化に気付ける

モニタリング用のデータセットは同じものを使い続けるのか(多分 違う)  
適当に都度作り直すのか どうやって作る?(取ってくる?)のか分からない  

#### 1.3.2  予測モデルをモジュール化をしてアルゴリズムのA/Bテストができるようにする
機械学習システムの全体像が理解できていないため  
どこをモジュール化すべきと言ってくれているのか具体的に理解できない  
各前処理 と 予測モデル生成の処理は分けるとして 他がよく分からない  

#### 1.3.3  モデルのバージョン管理をして，いつでも切り戻し可能にする
ソースコード, モデル, データ の3つをバージョン管理できるのが理想  

モデル(関数?)は どのソースコード, データから生成したかドキュメント化すると良い  

#### 1.3.4  データ処理のパイプラインごと保存する
機械学習システムのデータ パイプラインは以下  
`Originalデータ -> 前処理 -> 予測モデル生成 -> 予測値の取得`  
[1.3.3](#133--モデルのバージョン管理をしていつでも切り戻し可能にする)で指すソースコードには これらすべての処理を含めましょう という話？  

[TODO] scikit-learnに以下の機能があるらしいので この辺りを勉強すれば理解できるかも  
> 更に前処理やアルゴリズムのパイプラインを作成し、性能が最も良い組み合わせを保存することができます

#### 1.3.5  開発/本番環境の言語/フレームワークは揃える
これも見出しの通り  

マイクロサービス的なアーキ(REST APIでやり取り)に出来るなら必ずしも揃えないのもあり  
予測モデル開発 と アプリ開発で それぞれ得意な言語・フレームワークを使う  

---
### 1.4  機械学習を含めたシステムを成功させるには
成功には 以下の4者(兼務もあり)がチームに必要
- プロダクトに関するドメイン知識を持った人  
	解くべき課題は何か プロダクトのどこに機械学習の手法が必要か を考える  
	また Feature選定や データ収集の方法 を考える
- 統計や機会学習に明るい人  
	この本で説明してくれていることができる人  
- データ分析基盤を作れるエンジニアリング能力のある人  
	= データエンジニア: データを活用できるようにする分析基盤を作る人  
- 失敗しても構わないとリスクを取ってくれる責任者  
	機械学習のリスクを認識・理解したうえで お金取ってくれる/来てくれる 人  

---
### 1.5  この章のまとめ
機械学習プロジェクトの進め方とそのポイント まとめ  
- 解くべき問題の仮説を立て MVPを作りコンセプトの検証を最優先する [1.2.2](#122--機械学習をしなくて良い方法を考える)  
- 機械学習をしないことを恐れない [1.2.2](#122--機械学習をしなくて良い方法を考える)  
- 機械学習に適している問題設定かを見極める [1.2.2](#122--機械学習をしなくて良い方法を考える)  
- 予測性能とKPIの両方のモニタリングし、継続して改善を続ける [1.2.8](#128--システムに組み込む)  

## 2章  機械学習で何ができる？
### 2.1  どのアルゴリズムを選ぶべきか？
### 2.2  分類
#### 2.2.1  パーセプトロン
#### 2.2.2  ロジスティック回帰
#### 2.2.3  SVM
#### 2.2.4  ニューラルネットワーク
#### 2.2.5  k-NN
#### 2.2.6  決定木，ランダムフォレスト，GBDT
### 2.3  回帰
#### 2.3.1  線形回帰の仕組み
### 2.4  クラスタリング・次元削減
#### 2.4.1  クラスタリング
#### 2.4.2  次元削減
### 2.5  その他
#### 2.5.1  推薦
#### 2.5.2  異常検知
#### 2.5.3  頻出パターンマイニング
#### 2.5.4  強化学習
### 2.6  この章のまとめ
## 3章  学習結果を評価しよう
### 3.1  分類の評価
#### 3.1.1  正解率を使えば良いのか？
#### 3.1.2  データ数の偏りを考慮する適合率と再現率
#### 3.1.3  F値でバランスの良い性能を見る
#### 3.1.4  混同行列を知る
#### 3.1.5  多クラス分類の平均のとり方: マイクロ平均，マクロ平均
#### 3.1.6  分類モデルを比較する
### 3.2  回帰の評価
#### 3.2.1  平均二乗誤差
#### 3.2.2  決定係数
### 3.3  機械学習を組み込んだシステムのA/Bテスト
### 3.4  この章のまとめ
## 4章  システムに機械学習を組み込む
### 4.1  システムに機械学習を含める流れ
### 4.2  システム設計
#### 4.2.1  混乱しやすい「バッチ処理」と「バッチ学習」
#### 4.2.2  バッチ処理で学習＋予測結果をWebアプリケーションで直接算出する（リアルタイム処理で予測）
#### 4.2.3  バッチ処理で学習＋予測結果をAPI経由で利用する（リアルタイム処理で予測）
#### 4.2.4  バッチ処理で学習＋予測結果をDB経由で利用する（バッチ処理で予測）
#### 4.2.5  リアルタイム処理で学習をする
#### 4.2.6  各パターンのまとめ
### 4.3  ログ設計
#### 4.3.1  特徴量や教師データに使いうる情報
#### 4.3.2  ログを保持する場所
#### 4.3.3  ログを設計する上での注意点
### 4.4  この章のまとめ
## 5章  学習のためのリソースを収集しよう
### 5.1  学習のためのリソースの取得方法
### 5.2  公開されたデータセットやモデルを活用する
### 5.3  開発者自身が教師データを作る
### 5.4  同僚や友人などにデータ入力してもらう
### 5.5  クラウドソーシングを活用する
### 5.6  サービスに組み込み，ユーザに入力してもらう
### 5.7  この章のまとめ
## 6章  効果検証
### 6.1  効果検証の概要
#### 6.1.1  効果検証までの道程
#### 6.1.2  オフラインで検証しにくいポイント
### 6.2  仮説検定の枠組み
#### 6.2.1  コインは歪んでいるか
#### 6.2.2  二群の母比率の差の検定
#### 6.2.3  偽陽性と偽陰性
### 6.3  仮説検定の注意点
#### 6.3.1  繰り返し検定をしてしまう
#### 6.3.2  有意差とビジネスインパクト
#### 6.3.3  複数の検定を同時に行う
### 6.4  因果効果の推定
#### 6.4.1  ルービンの因果モデル
#### 6.4.2  セレクションバイアス
#### 6.4.3  ランダム化比較試験
#### 6.4.4  過去との比較は難しい
### 6.5  A/Bテスト
#### 6.5.1  2群の抽出と標本サイズ
#### 6.5.2  A/Aテストによる均質さの確認
#### 6.5.3  A/Bテストの仕組み作り
#### 6.5.4  テストの終了
### 6.6  この章のまとめ
## 第II部
## 7章  映画の推薦システムをつくる
### 7.1  シナリオ
#### 7.1.1  推薦システムとは
#### 7.1.2  応用シーン
### 7.2  推薦システムをもっと知ろう
#### 7.2.1  データの設計と取得
#### 7.2.2  明示的データと暗黙的データ
#### 7.2.3  推薦システムのアルゴリズム
#### 7.2.4  ユーザー間型協調フィルタリング
#### 7.2.5  アイテム間型協調フィルタリング
#### 7.2.6  モデルベース協調フィルタリング
#### 7.2.7  内容ベースフィルタリング
#### 7.2.8  協調フィルタリングと内容ベースフィルタリングの得手・不得手
#### 7.2.9  評価尺度
### 7.3  MovieLensのデータの傾向を見る
### 7.4  推薦システムの実装
#### 7.4.1  Factorization Machineを使った推薦
#### 7.4.2  いよいよFactorizatoin Machineで学習する
#### 7.4.3  ユーザーと映画以外のコンテキストも加える
### 7.5  この章のまとめ
## 8章  Kickstarterの分析，機械学習を使わないという選択肢
### 8.1  KickstarterのAPIを調査する
### 8.2  Kickstarterのクローラを作成する
### 8.3  JSONデータをCSVに変換する
### 8.4  Excelで軽く眺めてみる
### 8.5  ピボットテーブルでいろいろと眺めてみる
### 8.6  達成したのにキャンセルされたプロジェクトを見てみる
### 8.7  国別に見てみる
### 8.8  レポートを作る
### 8.9  今後行いたいこと
### 8.10  おわりに
## 9章  Uplift Modelingによるマーケティング資源の効率化
### 9.1  Uplift Modelingの四象限のセグメント
### 9.2  A/Bテストの拡張を通じたUplift Modelingの概要
### 9.3  Uplift Modelingのためのデータセット生成
### 9.4  2つの予測モデルを利用したUplift Modeling
### 9.5  Uplift Modellingの評価方法，AUUC
### 9.6  実践的な問題での活用
### 9.7  Uplift Modelingを本番投入するには
### 9.8  この章のまとめ
